{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourth Approach: Dimensionality reduction using PCA and re-sampling with SMOTE\n",
    "\n",
    "In this fouth approach, we will combine the approaches used in the second and third approach. We will preprocess the data by applying **Principal Component Analysis (PCA)** to reduce the dimensionality of the dataset, followed by **Synthetic Minority Over-sampling Technique (SMOTE)** to address class imbalance. First, we will load the data and apply PCA to all features to determine the optimal number of components, which will be selected based on the explained variance ratio. This allows us to retain as much of the data's variance as possible while reducing the dimensionality.\n",
    "\n",
    "After the PCA transformation, we will apply SMOTE to generate synthetic samples for the minority class, balancing the dataset before training the models. This combination of dimensionality reduction and oversampling is aimed at improving model performance, particularly on imbalanced datasets.\n",
    "\n",
    "To be able to compare the results with the rest of the approaches, we will use the same configuration of hyperparameters for the models:\n",
    "\n",
    "- **ANN**:\n",
    "  - Hidden layers: 1, number of neurons in the hidden layer: $[16, 32, 64]$.\n",
    "  - Hidden layers: 2, number of neurons in the hidden layers $[(16, 16), (32, 16), (32, 32), (64, 32), (64, 64)]$.\n",
    "- **Decision Tree**:\n",
    "  - Maximum depth of the tree $\\in \\{3, 5, 10, 15, 20, \\text{None}\\}$\n",
    "- **SVM**:\n",
    "  - Kernel $\\in \\{\\text{linear}, \\text{poly}, \\text{rbf}, \\text{sigmoid}\\}$\n",
    "  - C $\\in \\{0.1, 1, 10\\}$\n",
    "- **KNN\\***:\n",
    "  - $k \\in \\{1, 3, 5, 7, 9, 11, 13, 15\\}$\n",
    "\n",
    "After training the models, we will train an ensemble model with the three best models. The method used to combine the models will be:\n",
    "\n",
    "- **Majority voting**\n",
    "- **Weighted voting**\n",
    "- **Naive Bayes**\n",
    "- **Stacking** (using a logistic regression as the meta-model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Index**\n",
    "\n",
    "- [Data loading](#Data-loading)\n",
    "- [PCA Transformation](#PCA-Transformation)\n",
    "- [Individual models](#Individual-models)\n",
    "  - [ANN](#ANN)\n",
    "  - [Decision Tree](#Decision-Tree)\n",
    "  - [Support Vector Machine](#Support-Vector-Machine)\n",
    "  - [K-Nearest Neighbors](#K-Nearest-Neighbors)\n",
    "- [Ensemble model](#Ensemble-model)\n",
    "  - [Majority voting](#Majority-voting)\n",
    "  - [Weighted voting](#Weighted-voting)\n",
    "  - [Naive Bayes](#Naive-Bayes)\n",
    "  - [Stacking](#Stacking)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "using CSV\n",
    "using Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c anaconda conda` in root environment\n",
      "└ @ Conda /home/markel/.julia/packages/Conda/zReqD/src/Conda.jl:181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - anaconda\n",
      " - defaults\n",
      " - conda-forge\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/markel/.julia/conda/3/x86_64\n",
      "\n",
      "  added / updated specs:\n",
      "    - conda\n",
      "\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi            conda-forge/noarch::certifi-2024.8.30~ --> anaconda/linux-64::certifi-2024.8.30-py312h06a4308_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages: ...working... done\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y -c conda-forge 'libstdcxx-ng>=3.4,<13.0'` in root environment\n",
      "└ @ Conda /home/markel/.julia/packages/Conda/zReqD/src/Conda.jl:181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      " - anaconda\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/markel/.julia/conda/3/x86_64\n",
      "\n",
      "  added / updated specs:\n",
      "    - libstdcxx-ng[version='>=3.4,<13.0']\n",
      "\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi            anaconda/linux-64::certifi-2024.8.30-~ --> conda-forge/noarch::certifi-2024.8.30-pyhd8ed1ab_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages: ...working... done\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "generateComparisonTable (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load custom functions from provided files\n",
    "include(\"preprocessing.jl\")\n",
    "include(\"metrics.jl\")\n",
    "include(\"training.jl\")\n",
    "include(\"plotting.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>5×35 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">Marital status</th><th style = \"text-align: left;\">Application mode</th><th style = \"text-align: left;\">Application order</th><th style = \"text-align: left;\">Course</th><th style = \"text-align: left;\">Daytime/evening attendance</th><th style = \"text-align: left;\">Previous qualification</th><th style = \"text-align: left;\">Nacionality</th><th style = \"text-align: left;\">Mother&apos;s qualification</th><th style = \"text-align: left;\">Father&apos;s qualification</th><th style = \"text-align: left;\">Mother&apos;s occupation</th><th style = \"text-align: left;\">Father&apos;s occupation</th><th style = \"text-align: left;\">Displaced</th><th style = \"text-align: left;\">Educational special needs</th><th style = \"text-align: left;\">Debtor</th><th style = \"text-align: left;\">Tuition fees up to date</th><th style = \"text-align: left;\">Gender</th><th style = \"text-align: left;\">Scholarship holder</th><th style = \"text-align: left;\">Age at enrollment</th><th style = \"text-align: left;\">International</th><th style = \"text-align: left;\">Curricular units 1st sem (credited)</th><th style = \"text-align: left;\">Curricular units 1st sem (enrolled)</th><th style = \"text-align: left;\">Curricular units 1st sem (evaluations)</th><th style = \"text-align: left;\">Curricular units 1st sem (approved)</th><th style = \"text-align: left;\">Curricular units 1st sem (grade)</th><th style = \"text-align: left;\">Curricular units 1st sem (without evaluations)</th><th style = \"text-align: left;\">Curricular units 2nd sem (credited)</th><th style = \"text-align: left;\">Curricular units 2nd sem (enrolled)</th><th style = \"text-align: left;\">Curricular units 2nd sem (evaluations)</th><th style = \"text-align: left;\">Curricular units 2nd sem (approved)</th><th style = \"text-align: left;\">Curricular units 2nd sem (grade)</th><th style = \"text-align: left;\">Curricular units 2nd sem (without evaluations)</th><th style = \"text-align: left;\">Unemployment rate</th><th style = \"text-align: left;\">Inflation rate</th><th style = \"text-align: left;\">GDP</th><th style = \"text-align: left;\">Target</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"String15\" style = \"text-align: left;\">String15</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">8</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">13</td><td style = \"text-align: right;\">10</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">10</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">20</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">10.8</td><td style = \"text-align: right;\">1.4</td><td style = \"text-align: right;\">1.74</td><td style = \"text-align: left;\">Dropout</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">11</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">19</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">14.0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">13.6667</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">13.9</td><td style = \"text-align: right;\">-0.3</td><td style = \"text-align: right;\">0.79</td><td style = \"text-align: left;\">Graduate</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">22</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">10</td><td style = \"text-align: right;\">10</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">19</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">10.8</td><td style = \"text-align: right;\">1.4</td><td style = \"text-align: right;\">1.74</td><td style = \"text-align: left;\">Dropout</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">8</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">15</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">23</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">20</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">8</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">13.4286</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">10</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">12.4</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">9.4</td><td style = \"text-align: right;\">-0.8</td><td style = \"text-align: right;\">-3.12</td><td style = \"text-align: left;\">Graduate</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">12</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">22</td><td style = \"text-align: right;\">28</td><td style = \"text-align: right;\">10</td><td style = \"text-align: right;\">10</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">45</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">12.3333</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">13.0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">13.9</td><td style = \"text-align: right;\">-0.3</td><td style = \"text-align: right;\">0.79</td><td style = \"text-align: left;\">Graduate</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& Marital status & Application mode & Application order & Course & Daytime/evening attendance & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Int64 & Int64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 8 & 5 & 2 & 1 & $\\dots$ \\\\\n",
       "\t2 & 1 & 6 & 1 & 11 & 1 & $\\dots$ \\\\\n",
       "\t3 & 1 & 1 & 5 & 5 & 1 & $\\dots$ \\\\\n",
       "\t4 & 1 & 8 & 2 & 15 & 1 & $\\dots$ \\\\\n",
       "\t5 & 2 & 12 & 1 & 3 & 0 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×35 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Marital status \u001b[0m\u001b[1m Application mode \u001b[0m\u001b[1m Application order \u001b[0m\u001b[1m Course \u001b[0m\u001b[1m Daytime/ev\u001b[0m ⋯\n",
       "     │\u001b[90m Int64          \u001b[0m\u001b[90m Int64            \u001b[0m\u001b[90m Int64             \u001b[0m\u001b[90m Int64  \u001b[0m\u001b[90m Int64     \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │              1                 8                  5       2             ⋯\n",
       "   2 │              1                 6                  1      11\n",
       "   3 │              1                 1                  5       5\n",
       "   4 │              1                 8                  2      15\n",
       "   5 │              2                12                  1       3             ⋯\n",
       "\u001b[36m                                                              31 columns omitted\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the random seed for reproducibility\n",
    "Random.seed!(42)\n",
    "\n",
    "# Load the dataset\n",
    "dataset_path = \"dataset.csv\"\n",
    "data = CSV.read(dataset_path, DataFrame)\n",
    "data[1:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "target_column = :Target\n",
    "inputs = select(data, Not(target_column))\n",
    "targets = data[!, target_column];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded targets: [0, 1, 0, 1, 1]\n",
      "Decoded targets: [\"Dropout\", \"Graduate\", \"Dropout\", \"Graduate\", \"Graduate\"]\n"
     ]
    }
   ],
   "source": [
    "inputs = Float32.(Matrix(inputs))\n",
    "\n",
    "# Define the categories and their mapping\n",
    "label_mapping = Dict(\"Dropout\" => 0, \"Graduate\" => 1, \"Enrolled\" => 2)\n",
    "\n",
    "# Encode the targets\n",
    "targets_label_encoded = [label_mapping[label] for label in targets]\n",
    "\n",
    "println(\"Encoded targets: \", targets_label_encoded[1:5])\n",
    "\n",
    "# To decode later, create a reverse mapping\n",
    "reverse_mapping = Dict(v => k for (k, v) in label_mapping)\n",
    "decoded_targets = [reverse_mapping[code] for code in targets_label_encoded]\n",
    "\n",
    "println(\"Decoded targets: \", decoded_targets[1:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Float32.(Matrix(inputs))\n",
    "\n",
    "# Define the number of folds for cross-validation and obtain the indices\n",
    "Random.seed!(42)\n",
    "k = 5\n",
    "N = size(inputs, 1)\n",
    "fold_indices = crossValidation(targets, k)\n",
    "metrics_to_save = [:accuracy, :precision, :recall, :f1_score];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution:\n",
      "\u001b[1m3×2 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m Target   \u001b[0m\u001b[1m Count \u001b[0m\n",
      "     │\u001b[90m String15 \u001b[0m\u001b[90m Int64 \u001b[0m\n",
      "─────┼─────────────────\n",
      "   1 │ Dropout    1421\n",
      "   2 │ Graduate   2209\n",
      "   3 │ Enrolled    794\n"
     ]
    }
   ],
   "source": [
    "target_column = :Target\n",
    "println(\"\\nClass Distribution:\")\n",
    "println(combine(groupby(data, target_column), nrow => :Count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE Experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Smote percentages: Dict(\"Enrolled\" => 200)\n",
      "Number of instances: 5218\n",
      "Elements of class Dropout: 1421\n",
      "Elements of class Graduate: 2209\n",
      "Elements of class Enrolled: 1588\n",
      "\n",
      "Smote percentages: Dict(\"Enrolled\" => 300)\n",
      "Number of instances: 6012\n",
      "Elements of class Dropout: 1421\n",
      "Elements of class Graduate: 2209\n",
      "Elements of class Enrolled: 2382\n",
      "\n",
      "Smote percentages: Dict(\"Enrolled\" => 200, \"Dropout\" => 200)\n",
      "Number of instances: 6639\n",
      "Elements of class Dropout: 2842\n",
      "Elements of class Graduate: 2209\n",
      "Elements of class Enrolled: 1588\n",
      "\n",
      "Smote percentages: Dict(\"Enrolled\" => 300, \"Dropout\" => 200)\n",
      "Number of instances: 7433\n",
      "Elements of class Dropout: 2842\n",
      "Elements of class Graduate: 2209\n",
      "Elements of class Enrolled: 2382\n",
      "\n",
      "Smote percentages: Dict(\"Enrolled\" => 200, \"Graduate\" => 50)\n",
      "Number of instances: 4113\n",
      "Elements of class Dropout: 1421\n",
      "Elements of class Graduate: 1104\n",
      "Elements of class Enrolled: 1588\n"
     ]
    }
   ],
   "source": [
    "smote_percentages = [\n",
    "  Dict(\"Enrolled\" => 200),\n",
    "  Dict(\"Enrolled\" => 300),\n",
    "  Dict(\"Enrolled\" => 200, \"Dropout\" => 200),\n",
    "  Dict(\"Enrolled\" => 300, \"Dropout\" => 200),\n",
    "  Dict(\"Enrolled\" => 200, \"Graduate\" => 50)\n",
    "]\n",
    "k = 5\n",
    "\n",
    "open(\"warnings.log\", \"w\") do file\n",
    "  redirect_stderr(file) do # redirect warnings associated with joblib\n",
    "    for (i, smote_percentage) in enumerate(smote_percentages)\n",
    "      println(\"\\nSmote percentages: \", smote_percentage)\n",
    "      balanced_inputs, balanced_targets = smote(inputs, targets, smote_percentage, k)\n",
    "      println(\"Number of instances: \", size(balanced_targets)[1])\n",
    "      println(\"Elements of class Dropout: \", sum(balanced_targets .== \"Dropout\"))\n",
    "      println(\"Elements of class Graduate: \", sum(balanced_targets .== \"Graduate\"))\n",
    "      println(\"Elements of class Enrolled: \", sum(balanced_targets .== \"Enrolled\"))\n",
    "    end\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best configurations\n",
    "topology = [64, 32]\n",
    "topology_scikit_ann = [64]\n",
    "max_depth = 5\n",
    "n_neighbors = 5\n",
    "kernel = \"linear\"\n",
    "C = 10\n",
    "\n",
    "# ANN\n",
    "hyperparameters_ann = Dict(\n",
    "  \"topology\" => topology,\n",
    "  \"learningRate\" => 0.01,\n",
    "  \"maxEpochs\" => 100,\n",
    "  \"repetitionsTraining\" => 10,\n",
    "  \"validationRatio\" => 0.15,\n",
    "  \"maxEpochsVal\" => 10,\n",
    "  \"minLoss\" => 0.0001\n",
    ")\n",
    "\n",
    "# scikitANN\n",
    "hyperparameters_scikit_ann = Dict(\n",
    "  :hidden_layer_sizes => topology_scikit_ann,\n",
    "  :learning_rate_init => 0.01,\n",
    "  :max_iter => 100,\n",
    "  :early_stopping => true,\n",
    "  :tol => 0,\n",
    "  :validation_fraction => 0.15,\n",
    "  :n_iter_no_change => 10,\n",
    "  :epsilon => 0.0001,\n",
    "  :repetitionsTraining => 10\n",
    ")\n",
    "\n",
    "# DT\n",
    "hyperparameters_dt = Dict(\n",
    "  :max_depth => max_depth,\n",
    "  :criterion => \"gini\",\n",
    "  :min_samples_split => 2,\n",
    ")\n",
    "\n",
    "# SVM\n",
    "hyperparameters_svm = Dict(\n",
    "  :kernel => kernel,\n",
    "  :C => C,\n",
    "  :gamma => \"auto\",\n",
    "  :probability => true,\n",
    ")\n",
    "\n",
    "# KNN\n",
    "hyperparameters_knn = Dict(\n",
    "  :n_neighbors => n_neighbors,\n",
    "  :weights => \"uniform\",\n",
    "  :metric => \"euclidean\",\n",
    ")\n",
    "\n",
    "# Define the hyperparameters for smote\n",
    "k = 5\n",
    "smote_percentages = [\n",
    "  Dict(\"Enrolled\" => 200),\n",
    "  Dict(\"Enrolled\" => 300),\n",
    "  Dict(\"Enrolled\" => 200, \"Dropout\" => 200),\n",
    "  Dict(\"Enrolled\" => 300, \"Dropout\" => 200),\n",
    "  Dict(\"Enrolled\" => 200, \"Graduate\" => 50),\n",
    "  Dict{String,Int}()\n",
    "];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Smote percentage: Dict(\"Enrolled\" => 200)\n",
      "ANN\n",
      "Mean accuracy: 0.50329 ± 0.03332\n",
      "\tClass 1: 0.40221 ± 0.0872\n",
      "\tClass 2: 0.46878 ± 0.01671\n",
      "\tClass 3: 0.78019 ± 0.01686\n",
      "Mean precision: 0.18837 ± 0.03023\n",
      "\tClass 1: 0.23631 ± 0.03359\n",
      "\tClass 2: 0.19763 ± 0.06564\n",
      "\tClass 3: 0.07684 ± 0.04322\n",
      "Mean recall: 0.32559 ± 0.04436\n",
      "\tClass 1: 0.59687 ± 0.1737\n",
      "\tClass 2: 0.24289 ± 0.18126\n",
      "\tClass 3: 0.07023 ± 0.03771\n",
      "Mean f1_score: 0.19841 ± 0.03879\n",
      "\tClass 1: 0.31123 ± 0.08233\n",
      "\tClass 2: 0.18018 ± 0.12199\n",
      "\tClass 3: 0.04727 ± 0.0204\n",
      "scikitANN\n",
      "Mean accuracy: 0.82531 ± 0.00668\n",
      "\tClass 1: 0.82938 ± 0.01385\n",
      "\tClass 2: 0.82743 ± 0.01753\n",
      "\tClass 3: 0.8206 ± 0.01156\n",
      "Mean precision: 0.70965 ± 0.01797\n",
      "\tClass 1: 0.75658 ± 0.01411\n",
      "\tClass 2: 0.72655 ± 0.0294\n",
      "\tClass 3: 0.51406 ± 0.08018\n",
      "Mean recall: 0.7387 ± 0.011\n",
      "\tClass 1: 0.86209 ± 0.05551\n",
      "\tClass 2: 0.7516 ± 0.10567\n",
      "\tClass 3: 0.26931 ± 0.08956\n",
      "Mean f1_score: 0.70963 ± 0.01292\n",
      "\tClass 1: 0.80476 ± 0.02995\n",
      "\tClass 2: 0.72746 ± 0.07328\n",
      "\tClass 3: 0.33862 ± 0.08672\n",
      "DT\n",
      "Mean accuracy: 0.7743 ± 0.02742\n",
      "\tClass 1: 0.75545 ± 0.05874\n",
      "\tClass 2: 0.79883 ± 0.03799\n",
      "\tClass 3: 0.79385 ± 0.02993\n",
      "Mean precision: 0.6574 ± 0.0312\n",
      "\tClass 1: 0.71003 ± 0.07026\n",
      "\tClass 2: 0.67427 ± 0.20818\n",
      "\tClass 3: 0.43342 ± 0.21437\n",
      "Mean recall: 0.67407 ± 0.03657\n",
      "\tClass 1: 0.83086 ± 0.12847\n",
      "\tClass 2: 0.58205 ± 0.27453\n",
      "\tClass 3: 0.26914 ± 0.21438\n",
      "Mean f1_score: 0.64784 ± 0.03418\n",
      "\tClass 1: 0.75662 ± 0.04417\n",
      "\tClass 2: 0.61128 ± 0.22578\n",
      "\tClass 3: 0.31931 ± 0.22077\n",
      "SVM\n",
      "Mean accuracy: 0.82537 ± 0.00598\n",
      "\tClass 1: 0.83272 ± 0.01894\n",
      "\tClass 2: 0.82641 ± 0.0196\n",
      "\tClass 3: 0.816 ± 0.00399\n",
      "Mean precision: 0.71749 ± 0.01013\n",
      "\tClass 1: 0.76735 ± 0.01814\n",
      "\tClass 2: 0.70124 ± 0.15449\n",
      "\tClass 3: 0.54096 ± 0.14264\n",
      "Mean recall: 0.73757 ± 0.00751\n",
      "\tClass 1: 0.80797 ± 0.08616\n",
      "\tClass 2: 0.71588 ± 0.25208\n",
      "\tClass 3: 0.40785 ± 0.25266\n",
      "Mean f1_score: 0.72156 ± 0.00926\n",
      "\tClass 1: 0.7851 ± 0.04003\n",
      "\tClass 2: 0.70388 ± 0.20521\n",
      "\tClass 3: 0.45642 ± 0.2075\n",
      "KNN\n",
      "Mean accuracy: 0.78734 ± 0.01281\n",
      "\tClass 1: 0.80062 ± 0.02342\n",
      "\tClass 2: 0.78936 ± 0.04054\n",
      "\tClass 3: 0.77442 ± 0.01473\n",
      "Mean precision: 0.67795 ± 0.02262\n",
      "\tClass 1: 0.75275 ± 0.02471\n",
      "\tClass 2: 0.65554 ± 0.22562\n",
      "\tClass 3: 0.44745 ± 0.15976\n",
      "Mean recall: 0.6822 ± 0.02103\n",
      "\tClass 1: 0.7151 ± 0.10956\n",
      "\tClass 2: 0.6521 ± 0.25235\n",
      "\tClass 3: 0.43735 ± 0.20459\n",
      "Mean f1_score: 0.67687 ± 0.02096\n",
      "\tClass 1: 0.72956 ± 0.05461\n",
      "\tClass 2: 0.65042 ± 0.23112\n",
      "\tClass 3: 0.44148 ± 0.18165\n",
      "\n",
      "Smote percentage: Dict(\"Enrolled\" => 300)\n",
      "ANN\n",
      "Mean accuracy: 0.60748 ± 0.17281\n",
      "\tClass 1: 0.56843 ± 0.23258\n",
      "\tClass 2: 0.59021 ± 0.17284\n",
      "\tClass 3: 0.72516 ± 0.07915\n",
      "Mean precision: 0.36803 ± 0.26997\n",
      "\tClass 1: 0.40775 ± 0.25288\n",
      "\tClass 2: 0.39014 ± 0.32981\n",
      "\tClass 3: 0.23539 ± 0.14529\n",
      "Mean recall: 0.4419 ± 0.23639\n",
      "\tClass 1: 0.62604 ± 0.10616\n",
      "\tClass 2: 0.39678 ± 0.43281\n",
      "\tClass 3: 0.23799 ± 0.0614\n",
      "Mean f1_score: 0.36598 ± 0.27899\n",
      "\tClass 1: 0.46394 ± 0.21231\n",
      "\tClass 2: 0.36726 ± 0.39613\n",
      "\tClass 3: 0.18705 ± 0.08519\n",
      "scikitANN\n",
      "Mean accuracy: 0.82407 ± 0.00843\n",
      "\tClass 1: 0.83011 ± 0.01732\n",
      "\tClass 2: 0.82646 ± 0.01896\n",
      "\tClass 3: 0.81492 ± 0.01262\n",
      "Mean precision: 0.70755 ± 0.0217\n",
      "\tClass 1: 0.76499 ± 0.01049\n",
      "\tClass 2: 0.73894 ± 0.04094\n",
      "\tClass 3: 0.47464 ± 0.06782\n",
      "Mean recall: 0.73574 ± 0.01444\n",
      "\tClass 1: 0.84889 ± 0.06901\n",
      "\tClass 2: 0.79499 ± 0.09302\n",
      "\tClass 3: 0.24307 ± 0.02194\n",
      "Mean f1_score: 0.7107 ± 0.01586\n",
      "\tClass 1: 0.80337 ± 0.03383\n",
      "\tClass 2: 0.76243 ± 0.06266\n",
      "\tClass 3: 0.3161 ± 0.03397\n",
      "DT\n",
      "Mean accuracy: 0.77429 ± 0.01128\n",
      "\tClass 1: 0.76921 ± 0.03479\n",
      "\tClass 2: 0.77713 ± 0.03134\n",
      "\tClass 3: 0.7837 ± 0.04911\n",
      "Mean precision: 0.67526 ± 0.01279\n",
      "\tClass 1: 0.67669 ± 0.19229\n",
      "\tClass 2: 0.65362 ± 0.18502\n",
      "\tClass 3: 0.5248 ± 0.26284\n",
      "Mean recall: 0.66502 ± 0.02101\n",
      "\tClass 1: 0.68497 ± 0.2068\n",
      "\tClass 2: 0.62011 ± 0.25093\n",
      "\tClass 3: 0.44965 ± 0.14709\n",
      "Mean f1_score: 0.66075 ± 0.01327\n",
      "\tClass 1: 0.67028 ± 0.17141\n",
      "\tClass 2: 0.62793 ± 0.20398\n",
      "\tClass 3: 0.47882 ± 0.19615\n",
      "SVM\n",
      "Mean accuracy: 0.82302 ± 0.00468\n",
      "\tClass 1: 0.83566 ± 0.0163\n",
      "\tClass 2: 0.81195 ± 0.02129\n",
      "\tClass 3: 0.81487 ± 0.01998\n",
      "Mean precision: 0.72122 ± 0.00724\n",
      "\tClass 1: 0.78191 ± 0.02064\n",
      "\tClass 2: 0.63316 ± 0.19665\n",
      "\tClass 3: 0.58563 ± 0.19569\n",
      "Mean recall: 0.73124 ± 0.00724\n",
      "\tClass 1: 0.78943 ± 0.0883\n",
      "\tClass 2: 0.63774 ± 0.26305\n",
      "\tClass 3: 0.52639 ± 0.22889\n",
      "Mean f1_score: 0.72388 ± 0.00636\n",
      "\tClass 1: 0.78352 ± 0.04391\n",
      "\tClass 2: 0.63311 ± 0.22839\n",
      "\tClass 3: 0.55281 ± 0.21324\n",
      "KNN\n",
      "Mean accuracy: 0.78018 ± 0.01528\n",
      "\tClass 1: 0.79972 ± 0.0268\n",
      "\tClass 2: 0.78033 ± 0.04803\n",
      "\tClass 3: 0.75543 ± 0.01403\n",
      "Mean precision: 0.68526 ± 0.02063\n",
      "\tClass 1: 0.76968 ± 0.02932\n",
      "\tClass 2: 0.66554 ± 0.22412\n",
      "\tClass 3: 0.43141 ± 0.17171\n",
      "Mean recall: 0.66774 ± 0.0249\n",
      "\tClass 1: 0.68393 ± 0.10715\n",
      "\tClass 2: 0.64523 ± 0.19216\n",
      "\tClass 3: 0.48752 ± 0.15068\n",
      "Mean f1_score: 0.67248 ± 0.02243\n",
      "\tClass 1: 0.72017 ± 0.05634\n",
      "\tClass 2: 0.65085 ± 0.20078\n",
      "\tClass 3: 0.45716 ± 0.16244\n",
      "\n",
      "Smote percentage: Dict(\"Enrolled\" => 200, \"Dropout\" => 200)\n",
      "ANN\n",
      "Mean accuracy: 0.51512 ± 0.03668\n",
      "\tClass 1: 0.50618 ± 0.09711\n",
      "\tClass 2: 0.51391 ± 0.03089\n",
      "\tClass 3: 0.53446 ± 0.06984\n",
      "Mean precision: 0.26319 ± 0.073\n",
      "\tClass 1: 0.14991 ± 0.02595\n",
      "\tClass 2: 0.37917 ± 0.14168\n",
      "\tClass 3: 0.14332 ± 0.00948\n",
      "Mean recall: 0.27727 ± 0.0459\n",
      "\tClass 1: 0.24469 ± 0.12228\n",
      "\tClass 2: 0.2377 ± 0.15238\n",
      "\tClass 3: 0.44591 ± 0.13125\n",
      "Mean f1_score: 0.20033 ± 0.05052\n",
      "\tClass 1: 0.15917 ± 0.05729\n",
      "\tClass 2: 0.22868 ± 0.12342\n",
      "\tClass 3: 0.19526 ± 0.02718\n",
      "scikitANN\n",
      "Mean accuracy: 0.8097 ± 0.01028\n",
      "\tClass 1: 0.80976 ± 0.02417\n",
      "\tClass 2: 0.81647 ± 0.02467\n",
      "\tClass 3: 0.80977 ± 0.02022\n",
      "Mean precision: 0.7108 ± 0.01354\n",
      "\tClass 1: 0.76587 ± 0.06042\n",
      "\tClass 2: 0.69189 ± 0.10119\n",
      "\tClass 3: 0.54087 ± 0.12737\n",
      "Mean recall: 0.718 ± 0.01579\n",
      "\tClass 1: 0.85178 ± 0.13305\n",
      "\tClass 2: 0.59066 ± 0.17493\n",
      "\tClass 3: 0.39138 ± 0.09146\n",
      "Mean f1_score: 0.698 ± 0.01524\n",
      "\tClass 1: 0.79304 ± 0.0409\n",
      "\tClass 2: 0.62464 ± 0.11826\n",
      "\tClass 3: 0.44752 ± 0.1051\n",
      "DT\n",
      "Mean accuracy: 0.76173 ± 0.00686\n",
      "\tClass 1: 0.74231 ± 0.03876\n",
      "\tClass 2: 0.7873 ± 0.02962\n",
      "\tClass 3: 0.78504 ± 0.0112\n",
      "Mean precision: 0.65724 ± 0.02533\n",
      "\tClass 1: 0.70138 ± 0.07636\n",
      "\tClass 2: 0.77627 ± 0.07181\n",
      "\tClass 3: 0.35364 ± 0.05934\n",
      "Mean recall: 0.65733 ± 0.01033\n",
      "\tClass 1: 0.81948 ± 0.1766\n",
      "\tClass 2: 0.58929 ± 0.18111\n",
      "\tClass 3: 0.24938 ± 0.06611\n",
      "Mean f1_score: 0.63534 ± 0.01286\n",
      "\tClass 1: 0.73858 ± 0.06046\n",
      "\tClass 2: 0.65126 ± 0.07023\n",
      "\tClass 3: 0.29163 ± 0.0651\n",
      "SVM\n",
      "Mean accuracy: 0.81494 ± 0.00695\n",
      "\tClass 1: 0.82232 ± 0.02092\n",
      "\tClass 2: 0.82032 ± 0.02741\n",
      "\tClass 3: 0.80448 ± 0.01254\n",
      "Mean precision: 0.71647 ± 0.01009\n",
      "\tClass 1: 0.78388 ± 0.03553\n",
      "\tClass 2: 0.71292 ± 0.16928\n",
      "\tClass 3: 0.51104 ± 0.14079\n",
      "Mean recall: 0.72356 ± 0.01076\n",
      "\tClass 1: 0.8045 ± 0.13491\n",
      "\tClass 2: 0.65149 ± 0.17917\n",
      "\tClass 3: 0.45871 ± 0.23839\n",
      "Mean f1_score: 0.71374 ± 0.00993\n",
      "\tClass 1: 0.78671 ± 0.05178\n",
      "\tClass 2: 0.6771 ± 0.16154\n",
      "\tClass 3: 0.479 ± 0.18911\n",
      "KNN\n",
      "Mean accuracy: 0.78657 ± 0.00742\n",
      "\tClass 1: 0.80536 ± 0.02503\n",
      "\tClass 2: 0.78754 ± 0.03084\n",
      "\tClass 3: 0.77329 ± 0.01756\n",
      "Mean precision: 0.68208 ± 0.01091\n",
      "\tClass 1: 0.76792 ± 0.02492\n",
      "\tClass 2: 0.67001 ± 0.18409\n",
      "\tClass 3: 0.44363 ± 0.15675\n",
      "Mean recall: 0.6831 ± 0.01129\n",
      "\tClass 1: 0.71275 ± 0.12691\n",
      "\tClass 2: 0.65402 ± 0.21664\n",
      "\tClass 3: 0.44109 ± 0.21664\n",
      "Mean f1_score: 0.67725 ± 0.0108\n",
      "\tClass 1: 0.73303 ± 0.05527\n",
      "\tClass 2: 0.65626 ± 0.18522\n",
      "\tClass 3: 0.4409 ± 0.18486\n",
      "\n",
      "Smote percentage: Dict(\"Enrolled\" => 300, \"Dropout\" => 200)\n",
      "ANN\n",
      "Mean accuracy: 0.54151 ± 0.03653\n",
      "\tClass 1: 0.55018 ± 0.08005\n",
      "\tClass 2: 0.49076 ± 0.04437\n",
      "\tClass 3: 0.66721 ± 0.09728\n",
      "Mean precision: 0.29593 ± 0.03792\n",
      "\tClass 1: 0.14975 ± 0.07316\n",
      "\tClass 2: 0.46364 ± 0.05334\n",
      "\tClass 3: 0.09093 ± 0.02883\n",
      "Mean recall: 0.35408 ± 0.04641\n",
      "\tClass 1: 0.19179 ± 0.14396\n",
      "\tClass 2: 0.5021 ± 0.11771\n",
      "\tClass 3: 0.23259 ± 0.13502\n",
      "Mean f1_score: 0.26522 ± 0.04925\n",
      "\tClass 1: 0.13399 ± 0.08694\n",
      "\tClass 2: 0.40556 ± 0.09103\n",
      "\tClass 3: 0.10959 ± 0.03895\n",
      "scikitANN\n",
      "Mean accuracy: 0.81163 ± 0.0083\n",
      "\tClass 1: 0.81166 ± 0.02453\n",
      "\tClass 2: 0.81703 ± 0.02133\n",
      "\tClass 3: 0.81087 ± 0.02147\n",
      "Mean precision: 0.7162 ± 0.01243\n",
      "\tClass 1: 0.76213 ± 0.06515\n",
      "\tClass 2: 0.6928 ± 0.12073\n",
      "\tClass 3: 0.55952 ± 0.16735\n",
      "Mean recall: 0.71978 ± 0.013\n",
      "\tClass 1: 0.83705 ± 0.1265\n",
      "\tClass 2: 0.5966 ± 0.19928\n",
      "\tClass 3: 0.42933 ± 0.10236\n",
      "Mean f1_score: 0.70399 ± 0.0131\n",
      "\tClass 1: 0.78579 ± 0.04475\n",
      "\tClass 2: 0.6297 ± 0.14178\n",
      "\tClass 3: 0.48135 ± 0.12551\n",
      "DT\n",
      "Mean accuracy: 0.7541 ± 0.0127\n",
      "\tClass 1: 0.73916 ± 0.04716\n",
      "\tClass 2: 0.78142 ± 0.02839\n",
      "\tClass 3: 0.76334 ± 0.01129\n",
      "Mean precision: 0.65382 ± 0.01619\n",
      "\tClass 1: 0.70703 ± 0.08365\n",
      "\tClass 2: 0.77666 ± 0.06036\n",
      "\tClass 3: 0.32179 ± 0.02212\n",
      "Mean recall: 0.64196 ± 0.01635\n",
      "\tClass 1: 0.79461 ± 0.15981\n",
      "\tClass 2: 0.56002 ± 0.19096\n",
      "\tClass 3: 0.28724 ± 0.04671\n",
      "Mean f1_score: 0.6273 ± 0.01445\n",
      "\tClass 1: 0.73237 ± 0.05391\n",
      "\tClass 2: 0.63138 ± 0.07934\n",
      "\tClass 3: 0.30218 ± 0.03126\n",
      "SVM\n",
      "Mean accuracy: 0.81572 ± 0.00524\n",
      "\tClass 1: 0.82707 ± 0.01756\n",
      "\tClass 2: 0.80766 ± 0.02503\n",
      "\tClass 3: 0.80741 ± 0.01925\n",
      "Mean precision: 0.72297 ± 0.00938\n",
      "\tClass 1: 0.79542 ± 0.02967\n",
      "\tClass 2: 0.63927 ± 0.20134\n",
      "\tClass 3: 0.57671 ± 0.19788\n",
      "Mean recall: 0.72107 ± 0.0079\n",
      "\tClass 1: 0.79505 ± 0.1227\n",
      "\tClass 2: 0.60448 ± 0.17954\n",
      "\tClass 3: 0.54757 ± 0.20051\n",
      "Mean f1_score: 0.71749 ± 0.00744\n",
      "\tClass 1: 0.78938 ± 0.05094\n",
      "\tClass 2: 0.61688 ± 0.17768\n",
      "\tClass 3: 0.56022 ± 0.19401\n",
      "KNN\n",
      "Mean accuracy: 0.77855 ± 0.00959\n",
      "\tClass 1: 0.80174 ± 0.04062\n",
      "\tClass 2: 0.78348 ± 0.03539\n",
      "\tClass 3: 0.74977 ± 0.01415\n",
      "Mean precision: 0.68934 ± 0.01309\n",
      "\tClass 1: 0.7912 ± 0.04733\n",
      "\tClass 2: 0.60281 ± 0.23438\n",
      "\tClass 3: 0.49397 ± 0.21464\n",
      "Mean recall: 0.6675 ± 0.01379\n",
      "\tClass 1: 0.67753 ± 0.10178\n",
      "\tClass 2: 0.56782 ± 0.16878\n",
      "\tClass 3: 0.57339 ± 0.2113\n",
      "Mean f1_score: 0.67213 ± 0.01188\n",
      "\tClass 1: 0.7238 ± 0.03836\n",
      "\tClass 2: 0.57896 ± 0.18975\n",
      "\tClass 3: 0.53013 ± 0.21417\n",
      "\n",
      "Smote percentage: Dict(\"Enrolled\" => 200, \"Graduate\" => 50)\n",
      "ANN\n",
      "Mean accuracy: 0.67837 ± 0.01967\n",
      "\tClass 1: 0.73066 ± 0.01695\n",
      "\tClass 2: 0.60464 ± 0.036\n",
      "\tClass 3: 0.78992 ± 0.01872\n",
      "Mean precision: 0.50808 ± 0.0442\n",
      "\tClass 1: 0.61708 ± 0.12438\n",
      "\tClass 2: 0.58862 ± 0.0431\n",
      "\tClass 3: 0.0891 ± 0.05722\n",
      "Mean recall: 0.56261 ± 0.01952\n",
      "\tClass 1: 0.45687 ± 0.13948\n",
      "\tClass 2: 0.82028 ± 0.08139\n",
      "\tClass 3: 0.03513 ± 0.02007\n",
      "Mean f1_score: 0.49251 ± 0.03088\n",
      "\tClass 1: 0.46299 ± 0.0832\n",
      "\tClass 2: 0.6729 ± 0.01682\n",
      "\tClass 3: 0.04355 ± 0.02231\n",
      "scikitANN\n",
      "Mean accuracy: 0.67056 ± 0.05757\n",
      "\tClass 1: 0.62875 ± 0.07135\n",
      "\tClass 2: 0.68511 ± 0.03661\n",
      "\tClass 3: 0.746 ± 0.05305\n",
      "Mean precision: 0.65253 ± 0.02892\n",
      "\tClass 1: 0.45973 ± 0.05988\n",
      "\tClass 2: 0.72999 ± 0.08382\n",
      "\tClass 3: 0.51317 ± 0.08871\n",
      "Mean recall: 0.52993 ± 0.07552\n",
      "\tClass 1: 0.80859 ± 0.11105\n",
      "\tClass 2: 0.4448 ± 0.18186\n",
      "\tClass 3: 0.30766 ± 0.04922\n",
      "Mean f1_score: 0.50795 ± 0.10535\n",
      "\tClass 1: 0.56695 ± 0.04047\n",
      "\tClass 2: 0.50116 ± 0.15496\n",
      "\tClass 3: 0.36505 ± 0.07904\n",
      "DT\n",
      "Mean accuracy: 0.64131 ± 0.0547\n",
      "\tClass 1: 0.66743 ± 0.07739\n",
      "\tClass 2: 0.65192 ± 0.02834\n",
      "\tClass 3: 0.63173 ± 0.07284\n",
      "Mean precision: 0.56799 ± 0.0618\n",
      "\tClass 1: 0.49976 ± 0.06441\n",
      "\tClass 2: 0.55461 ± 0.31207\n",
      "\tClass 3: 0.40905 ± 0.23671\n",
      "Mean recall: 0.47553 ± 0.06645\n",
      "\tClass 1: 0.76497 ± 0.05886\n",
      "\tClass 2: 0.37641 ± 0.07633\n",
      "\tClass 3: 0.31538 ± 0.15585\n",
      "Mean f1_score: 0.46176 ± 0.11004\n",
      "\tClass 1: 0.60005 ± 0.03774\n",
      "\tClass 2: 0.4223 ± 0.15956\n",
      "\tClass 3: 0.29659 ± 0.14813\n",
      "SVM\n",
      "Mean accuracy: 0.75366 ± 0.00689\n",
      "\tClass 1: 0.77124 ± 0.0179\n",
      "\tClass 2: 0.74571 ± 0.02209\n",
      "\tClass 3: 0.7507 ± 0.02551\n",
      "Mean precision: 0.68435 ± 0.00293\n",
      "\tClass 1: 0.62205 ± 0.15704\n",
      "\tClass 2: 0.58981 ± 0.2578\n",
      "\tClass 3: 0.6062 ± 0.24964\n",
      "Mean recall: 0.63382 ± 0.01369\n",
      "\tClass 1: 0.69588 ± 0.15843\n",
      "\tClass 2: 0.58629 ± 0.16162\n",
      "\tClass 3: 0.55103 ± 0.15799\n",
      "Mean f1_score: 0.64068 ± 0.01219\n",
      "\tClass 1: 0.64597 ± 0.11524\n",
      "\tClass 2: 0.57196 ± 0.17361\n",
      "\tClass 3: 0.56211 ± 0.16258\n",
      "KNN\n",
      "Mean accuracy: 0.70413 ± 0.01628\n",
      "\tClass 1: 0.72398 ± 0.04861\n",
      "\tClass 2: 0.70188 ± 0.02933\n",
      "\tClass 3: 0.68853 ± 0.01868\n",
      "Mean precision: 0.6609 ± 0.00966\n",
      "\tClass 1: 0.58589 ± 0.19436\n",
      "\tClass 2: 0.50384 ± 0.21657\n",
      "\tClass 3: 0.6315 ± 0.30568\n",
      "Mean recall: 0.55719 ± 0.02468\n",
      "\tClass 1: 0.64028 ± 0.11991\n",
      "\tClass 2: 0.61666 ± 0.10617\n",
      "\tClass 3: 0.46445 ± 0.05309\n",
      "Mean f1_score: 0.57041 ± 0.02618\n",
      "\tClass 1: 0.58867 ± 0.11885\n",
      "\tClass 2: 0.53216 ± 0.13235\n",
      "\tClass 3: 0.4966 ± 0.11812\n",
      "\n",
      "Smote percentage: Dict{String, Int64}()\n",
      "ANN\n",
      "Mean accuracy: 0.55362 ± 0.08422\n",
      "\tClass 1: 0.50014 ± 0.14929\n",
      "\tClass 2: 0.51153 ± 0.09785\n",
      "\tClass 3: 0.76631 ± 0.07322\n",
      "Mean precision: 0.26561 ± 0.10262\n",
      "\tClass 1: 0.21062 ± 0.06852\n",
      "\tClass 2: 0.37829 ± 0.20894\n",
      "\tClass 3: 0.0504 ± 0.03927\n",
      "Mean recall: 0.38899 ± 0.08986\n",
      "\tClass 1: 0.34459 ± 0.26784\n",
      "\tClass 2: 0.53546 ± 0.32529\n",
      "\tClass 3: 0.061 ± 0.08435\n",
      "Mean f1_score: 0.27223 ± 0.0839\n",
      "\tClass 1: 0.19071 ± 0.14018\n",
      "\tClass 2: 0.40788 ± 0.24191\n",
      "\tClass 3: 0.04071 ± 0.04702\n",
      "scikitANN\n",
      "Mean accuracy: 0.83709 ± 0.00459\n",
      "\tClass 1: 0.84346 ± 0.01482\n",
      "\tClass 2: 0.83627 ± 0.01757\n",
      "\tClass 3: 0.82729 ± 0.02064\n",
      "Mean precision: 0.7389 ± 0.00997\n",
      "\tClass 1: 0.79477 ± 0.01228\n",
      "\tClass 2: 0.71027 ± 0.0972\n",
      "\tClass 3: 0.57886 ± 0.13191\n",
      "Mean recall: 0.75351 ± 0.0087\n",
      "\tClass 1: 0.83384 ± 0.07067\n",
      "\tClass 2: 0.6965 ± 0.19083\n",
      "\tClass 3: 0.46425 ± 0.1607\n",
      "Mean f1_score: 0.74043 ± 0.00861\n",
      "\tClass 1: 0.81124 ± 0.02909\n",
      "\tClass 2: 0.69568 ± 0.14869\n",
      "\tClass 3: 0.50934 ± 0.15083\n",
      "DT\n",
      "Mean accuracy: 0.78726 ± 0.00787\n",
      "\tClass 1: 0.77554 ± 0.04322\n",
      "\tClass 2: 0.80922 ± 0.04066\n",
      "\tClass 3: 0.79678 ± 0.02831\n",
      "Mean precision: 0.68963 ± 0.01305\n",
      "\tClass 1: 0.7366 ± 0.08199\n",
      "\tClass 2: 0.71893 ± 0.18728\n",
      "\tClass 3: 0.47337 ± 0.23008\n",
      "Mean recall: 0.69077 ± 0.01337\n",
      "\tClass 1: 0.84243 ± 0.12958\n",
      "\tClass 2: 0.584 ± 0.26692\n",
      "\tClass 3: 0.33421 ± 0.15634\n",
      "Mean f1_score: 0.67195 ± 0.01358\n",
      "\tClass 1: 0.77466 ± 0.02764\n",
      "\tClass 2: 0.62663 ± 0.20969\n",
      "\tClass 3: 0.38623 ± 0.18423\n",
      "SVM\n",
      "Mean accuracy: 0.82925 ± 0.00431\n",
      "\tClass 1: 0.83701 ± 0.02296\n",
      "\tClass 2: 0.82574 ± 0.01985\n",
      "\tClass 3: 0.8264 ± 0.01993\n",
      "Mean precision: 0.73035 ± 0.00444\n",
      "\tClass 1: 0.78879 ± 0.02097\n",
      "\tClass 2: 0.66164 ± 0.16153\n",
      "\tClass 3: 0.61136 ± 0.16966\n",
      "Mean recall: 0.74458 ± 0.0056\n",
      "\tClass 1: 0.79042 ± 0.09898\n",
      "\tClass 2: 0.65061 ± 0.28538\n",
      "\tClass 3: 0.52676 ± 0.27109\n",
      "Mean f1_score: 0.73179 ± 0.00387\n",
      "\tClass 1: 0.78611 ± 0.03857\n",
      "\tClass 2: 0.64915 ± 0.22577\n",
      "\tClass 3: 0.55848 ± 0.22308\n",
      "KNN\n",
      "Mean accuracy: 0.79301 ± 0.00586\n",
      "\tClass 1: 0.79859 ± 0.02058\n",
      "\tClass 2: 0.79771 ± 0.03033\n",
      "\tClass 3: 0.79205 ± 0.01111\n",
      "Mean precision: 0.67579 ± 0.00984\n",
      "\tClass 1: 0.73341 ± 0.01784\n",
      "\tClass 2: 0.66287 ± 0.17307\n",
      "\tClass 3: 0.47003 ± 0.15476\n",
      "Mean recall: 0.69418 ± 0.01066\n",
      "\tClass 1: 0.73934 ± 0.09765\n",
      "\tClass 2: 0.67937 ± 0.24634\n",
      "\tClass 3: 0.39265 ± 0.25538\n",
      "Mean f1_score: 0.6808 ± 0.00953\n",
      "\tClass 1: 0.73433 ± 0.05353\n",
      "\tClass 2: 0.66759 ± 0.20885\n",
      "\tClass 3: 0.42112 ± 0.20807\n"
     ]
    }
   ],
   "source": [
    "Random.seed!(42)\n",
    "\n",
    "general_results_ann = []\n",
    "class_results_ann = []\n",
    "general_results_scikit_ann = []\n",
    "class_results_scikit_ann = []\n",
    "general_results_dt = []\n",
    "class_results_dt = []\n",
    "general_results_svm = []\n",
    "class_results_svm = []\n",
    "general_results_knn = []\n",
    "class_results_knn = []\n",
    "\n",
    "open(\"warnings.log\", \"w\") do file\n",
    "  redirect_stderr(file) do # redirect warnings associated with joblib\n",
    "    for smote_percentage in smote_percentages\n",
    "      println(\"\\nSmote percentage: \", smote_percentage)\n",
    "\n",
    "      # ANN\n",
    "      println(\"ANN\")\n",
    "      gr, cr = modelCrossValidation(\n",
    "        :ANN,\n",
    "        hyperparameters_ann,\n",
    "        inputs,\n",
    "        targets,\n",
    "        fold_indices;\n",
    "        metricsToSave=metrics_to_save,\n",
    "        normalizationType=:zeroMean,\n",
    "        applyPCA=true,\n",
    "        pcaComponents=0.95,\n",
    "        applySmote=true,\n",
    "        smotePercentages=smote_percentage,\n",
    "        smoteNeighbors=k,\n",
    "        verbose=false\n",
    "      )\n",
    "      push!(general_results_ann, gr)\n",
    "      push!(class_results_ann, cr)\n",
    "\n",
    "      # Scikit ANN\n",
    "      println(\"scikitANN\")\n",
    "      gr, cr = modelCrossValidation(\n",
    "        :scikit_ANN,\n",
    "        hyperparameters_scikit_ann,\n",
    "        inputs,\n",
    "        targets,\n",
    "        fold_indices;\n",
    "        metricsToSave=metrics_to_save,\n",
    "        normalizationType=:zeroMean,\n",
    "        applyPCA=true,\n",
    "        pcaComponents=0.95,\n",
    "        applySmote=true,\n",
    "        smotePercentages=smote_percentage,\n",
    "        smoteNeighbors=k,\n",
    "        verbose=false\n",
    "      )\n",
    "\n",
    "      push!(general_results_scikit_ann, gr)\n",
    "      push!(class_results_scikit_ann, cr)\n",
    "\n",
    "      # DT\n",
    "      println(\"DT\")\n",
    "      gr, cr = modelCrossValidation(\n",
    "        :DT,\n",
    "        hyperparameters_dt,\n",
    "        inputs,\n",
    "        targets,\n",
    "        fold_indices;\n",
    "        metricsToSave=metrics_to_save,\n",
    "        normalizationType=:zeroMean,\n",
    "        applyPCA=true,\n",
    "        pcaComponents=0.95,\n",
    "        applySmote=true,\n",
    "        smotePercentages=smote_percentage,\n",
    "        smoteNeighbors=k,\n",
    "        verbose=false\n",
    "      )\n",
    "      push!(general_results_dt, gr)\n",
    "      push!(class_results_dt, cr)\n",
    "\n",
    "      # SVM\n",
    "      println(\"SVM\")\n",
    "      gr, cr = modelCrossValidation(\n",
    "        :SVC,\n",
    "        hyperparameters_svm,\n",
    "        inputs,\n",
    "        targets,\n",
    "        fold_indices;\n",
    "        metricsToSave=metrics_to_save,\n",
    "        normalizationType=:zeroMean,\n",
    "        applyPCA=true,\n",
    "        pcaComponents=0.95,\n",
    "        applySmote=true,\n",
    "        smotePercentages=smote_percentage,\n",
    "        smoteNeighbors=k,\n",
    "        verbose=false\n",
    "      )\n",
    "      push!(general_results_svm, gr)\n",
    "      push!(class_results_svm, cr)\n",
    "\n",
    "      # KNN\n",
    "      println(\"KNN\")\n",
    "      gr, cr = modelCrossValidation(\n",
    "        :KNN,\n",
    "        hyperparameters_knn,\n",
    "        inputs,\n",
    "        targets,\n",
    "        fold_indices;\n",
    "        metricsToSave=metrics_to_save,\n",
    "        normalizationType=:zeroMean,\n",
    "        applyPCA=true,\n",
    "        pcaComponents=0.95,\n",
    "        applySmote=true,\n",
    "        smotePercentages=smote_percentage,\n",
    "        smoteNeighbors=k,\n",
    "        verbose=false\n",
    "      )\n",
    "      push!(general_results_knn, gr)\n",
    "      push!(class_results_knn, cr)\n",
    "    end\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the results and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "results_folder = \"results/\"\n",
    "if !isdir(results_folder)\n",
    "  mkdir(results_folder)\n",
    "end\n",
    "\n",
    "filename = results_folder * \"4_smote_results.jl\"\n",
    "\n",
    "parameters = Dict(\"Enrolled\" => [200, 300, 200, 300, 200, 100], \"Dropout\" => [100, 100, 200, 200, 100, 100], \"Graduate\" => [100, 100, 100, 100, 50, 100])\n",
    "\n",
    "# Create a dictionary with the results of ANN, DT, SVM, and KNN\n",
    "obj = Dict(\n",
    "  :ANN => Dict(\n",
    "    \"num_trained_models\" => length(general_results_ann),\n",
    "    \"parameters\" => parameters,\n",
    "    \"general_results\" => general_results_ann,\n",
    "    \"class_results\" => class_results_ann\n",
    "  ),\n",
    "  :scikit_ANN => Dict(\n",
    "    \"num_trained_models\" => length(general_results_scikit_ann),\n",
    "    \"parameters\" => parameters,\n",
    "    \"general_results\" => general_results_scikit_ann,\n",
    "    \"class_results\" => class_results_scikit_ann\n",
    "  ),\n",
    "  :DT => Dict(\n",
    "    \"num_trained_models\" => length(general_results_dt),\n",
    "    \"parameters\" => parameters,\n",
    "    \"general_results\" => general_results_dt,\n",
    "    \"class_results\" => class_results_dt\n",
    "  ),\n",
    "  :SVM => Dict(\n",
    "    \"num_trained_models\" => length(general_results_svm),\n",
    "    \"parameters\" => parameters,\n",
    "    \"general_results\" => general_results_svm,\n",
    "    \"class_results\" => class_results_svm\n",
    "  ),\n",
    "  :KNN => Dict(\n",
    "    \"num_trained_models\" => length(general_results_knn),\n",
    "    \"parameters\" => parameters,\n",
    "    \"general_results\" => general_results_knn,\n",
    "    \"class_results\" => class_results_knn\n",
    "  )\n",
    ")\n",
    "\n",
    "# Save the results\n",
    "open(filename, \"w\") do file\n",
    "  serialize(file, obj)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = \"results/\"\n",
    "filename = results_folder * \"4_smote_results.jl\"\n",
    "\n",
    "# Load the results\n",
    "loaded_obj = open(filename, \"r\") do file\n",
    "  deserialize(file)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison of Hyperparameter Configurations for DT (Sorted by F1_Score):\n",
      "┌────────────────────────────────────────────┬──────────┬───────────┬──────────┬──────────┐\n",
      "│\u001b[1m                              Configuration \u001b[0m│\u001b[1m Accuracy \u001b[0m│\u001b[1m Precision \u001b[0m│\u001b[1m   Recall \u001b[0m│\u001b[1m F1-Score \u001b[0m│\n",
      "├────────────────────────────────────────────┼──────────┼───────────┼──────────┼──────────┤\n",
      "│ Enrolled: 100, Graduate: 100, Dropout: 100 │ 0.798931 │  0.710279 │ 0.703955 │ 0.695744 │\n",
      "│ Enrolled: 300, Graduate: 100, Dropout: 100 │ 0.783759 │  0.693434 │ 0.680226 │ 0.676134 │\n",
      "│ Enrolled: 200, Graduate: 100, Dropout: 100 │ 0.791587 │  0.680377 │ 0.703955 │ 0.672764 │\n",
      "│ Enrolled: 200, Graduate: 100, Dropout: 200 │ 0.769236 │  0.677612 │ 0.667797 │ 0.649467 │\n",
      "│ Enrolled: 300, Graduate: 100, Dropout: 200 │ 0.766547 │  0.670212 │ 0.661017 │ 0.643035 │\n",
      "│  Enrolled: 200, Graduate: 50, Dropout: 100 │  0.68154 │  0.611539 │ 0.529944 │ 0.539169 │\n",
      "└────────────────────────────────────────────┴──────────┴───────────┴──────────┴──────────┘\n",
      "Results for DT saved to ./tables/Approach4/smote/.\n",
      "\n",
      "Comparison of Hyperparameter Configurations for KNN (Sorted by F1_Score):\n",
      "┌────────────────────────────────────────────┬──────────┬───────────┬──────────┬──────────┐\n",
      "│\u001b[1m                              Configuration \u001b[0m│\u001b[1m Accuracy \u001b[0m│\u001b[1m Precision \u001b[0m│\u001b[1m   Recall \u001b[0m│\u001b[1m F1-Score \u001b[0m│\n",
      "├────────────────────────────────────────────┼──────────┼───────────┼──────────┼──────────┤\n",
      "│ Enrolled: 300, Graduate: 100, Dropout: 100 │ 0.795488 │  0.707663 │ 0.693785 │ 0.695151 │\n",
      "│ Enrolled: 200, Graduate: 100, Dropout: 100 │ 0.798064 │  0.694796 │ 0.699887 │ 0.694463 │\n",
      "│ Enrolled: 100, Graduate: 100, Dropout: 100 │ 0.800295 │  0.684645 │ 0.706682 │ 0.691126 │\n",
      "│ Enrolled: 200, Graduate: 100, Dropout: 200 │ 0.793164 │  0.693576 │ 0.696045 │ 0.688094 │\n",
      "│ Enrolled: 300, Graduate: 100, Dropout: 200 │ 0.789361 │  0.703021 │ 0.685876 │ 0.686375 │\n",
      "│  Enrolled: 200, Graduate: 50, Dropout: 100 │ 0.718103 │  0.672556 │ 0.580791 │ 0.593717 │\n",
      "└────────────────────────────────────────────┴──────────┴───────────┴──────────┴──────────┘\n",
      "Results for KNN saved to ./tables/Approach4/smote/.\n",
      "\n",
      "Comparison of Hyperparameter Configurations for SVM (Sorted by F1_Score):\n",
      "┌────────────────────────────────────────────┬──────────┬───────────┬──────────┬──────────┐\n",
      "│\u001b[1m                              Configuration \u001b[0m│\u001b[1m Accuracy \u001b[0m│\u001b[1m Precision \u001b[0m│\u001b[1m   Recall \u001b[0m│\u001b[1m F1-Score \u001b[0m│\n",
      "├────────────────────────────────────────────┼──────────┼───────────┼──────────┼──────────┤\n",
      "│ Enrolled: 200, Graduate: 100, Dropout: 100 │  0.83416 │  0.732633 │ 0.748023 │ 0.735294 │\n",
      "│ Enrolled: 100, Graduate: 100, Dropout: 100 │ 0.834801 │  0.733766 │ 0.749153 │ 0.734295 │\n",
      "│ Enrolled: 300, Graduate: 100, Dropout: 100 │ 0.828293 │  0.730646 │ 0.736723 │ 0.731269 │\n",
      "│ Enrolled: 200, Graduate: 100, Dropout: 200 │ 0.824563 │  0.728312 │ 0.736723 │ 0.725226 │\n",
      "│ Enrolled: 300, Graduate: 100, Dropout: 200 │ 0.820718 │  0.731029 │ 0.727684 │ 0.722769 │\n",
      "│  Enrolled: 200, Graduate: 50, Dropout: 100 │  0.75909 │  0.687621 │ 0.640997 │ 0.648628 │\n",
      "└────────────────────────────────────────────┴──────────┴───────────┴──────────┴──────────┘\n",
      "Results for SVM saved to ./tables/Approach4/smote/.\n",
      "\n",
      "Comparison of Hyperparameter Configurations for scikit_ANN (Sorted by F1_Score):\n",
      "┌────────────────────────────────────────────┬──────────┬───────────┬──────────┬──────────┐\n",
      "│\u001b[1m                              Configuration \u001b[0m│\u001b[1m Accuracy \u001b[0m│\u001b[1m Precision \u001b[0m│\u001b[1m   Recall \u001b[0m│\u001b[1m F1-Score \u001b[0m│\n",
      "├────────────────────────────────────────────┼──────────┼───────────┼──────────┼──────────┤\n",
      "│ Enrolled: 100, Graduate: 100, Dropout: 100 │ 0.841647 │  0.749014 │ 0.762599 │ 0.748872 │\n",
      "│ Enrolled: 300, Graduate: 100, Dropout: 100 │ 0.832579 │  0.726109 │ 0.749379 │ 0.722875 │\n",
      "│ Enrolled: 300, Graduate: 100, Dropout: 200 │ 0.824063 │  0.733893 │ 0.738531 │ 0.721661 │\n",
      "│ Enrolled: 200, Graduate: 100, Dropout: 100 │ 0.831349 │  0.725573 │ 0.747345 │ 0.720952 │\n",
      "│ Enrolled: 200, Graduate: 100, Dropout: 200 │ 0.818259 │  0.724304 │ 0.731186 │ 0.711961 │\n",
      "│  Enrolled: 200, Graduate: 50, Dropout: 100 │ 0.718111 │  0.686199 │ 0.593672 │ 0.588629 │\n",
      "└────────────────────────────────────────────┴──────────┴───────────┴──────────┴──────────┘\n",
      "Results for scikit_ANN saved to ./tables/Approach4/smote/.\n",
      "\n",
      "Comparison of Hyperparameter Configurations for ANN (Sorted by F1_Score):\n",
      "┌────────────────────────────────────────────┬──────────┬───────────┬──────────┬──────────┐\n",
      "│\u001b[1m                              Configuration \u001b[0m│\u001b[1m Accuracy \u001b[0m│\u001b[1m Precision \u001b[0m│\u001b[1m   Recall \u001b[0m│\u001b[1m F1-Score \u001b[0m│\n",
      "├────────────────────────────────────────────┼──────────┼───────────┼──────────┼──────────┤\n",
      "│ Enrolled: 300, Graduate: 100, Dropout: 100 │ 0.821546 │  0.703335 │ 0.733749 │ 0.706389 │\n",
      "│  Enrolled: 200, Graduate: 50, Dropout: 100 │ 0.711125 │  0.552998 │ 0.590395 │  0.54616 │\n",
      "│ Enrolled: 100, Graduate: 100, Dropout: 100 │ 0.654705 │  0.394031 │ 0.506908 │ 0.382239 │\n",
      "│ Enrolled: 300, Graduate: 100, Dropout: 200 │ 0.586579 │  0.337234 │ 0.425085 │ 0.333845 │\n",
      "│ Enrolled: 200, Graduate: 100, Dropout: 200 │ 0.554624 │  0.368855 │ 0.326727 │ 0.268098 │\n",
      "│ Enrolled: 200, Graduate: 100, Dropout: 100 │ 0.535456 │  0.225548 │ 0.370282 │ 0.229428 │\n",
      "└────────────────────────────────────────────┴──────────┴───────────┴──────────┴──────────┘\n",
      "Results for ANN saved to ./tables/Approach4/smote/.\n"
     ]
    }
   ],
   "source": [
    "# Generate tables for each algorithm sorted by f1 score\n",
    "generateAlgorithmTables(loaded_obj, sort_by=:F1_Score, rev=true, output_dir=\"./tables/Approach4/smote/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN\n",
    "\n",
    "We are going to start with our implementation for Artificial Neural Networks. To augment the robustness of the model, we will train each architecture 10 times with each fold of the cross-validation.\n",
    "\n",
    "We trained 8 models, 3 with one hidden layer and 5 with two hidden layers. The used topology for the hidden layers are:\n",
    "\n",
    "- **One hidden layer**:\n",
    "  - 16 neurons\n",
    "  - 32 neurons\n",
    "  - 64 neurons\n",
    "- **Two hidden layers**:\n",
    "  - (16, 16) neurons\n",
    "  - (32, 16) neurons\n",
    "  - (32, 32) neurons\n",
    "  - (64, 32) neurons\n",
    "  - (64, 64) neurons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ANN with topology: [64, 32]\n",
      "Mean accuracy: 0.65977 ± 0.05269\n",
      "\tClass 1: 0.63897 ± 0.04789\n",
      "\tClass 2: 0.62719 ± 0.08745\n",
      "\tClass 3: 0.78764 ± 0.02467\n",
      "Mean precision: 0.45517 ± 0.06839\n",
      "\tClass 1: 0.41495 ± 0.07752\n",
      "\tClass 2: 0.61874 ± 0.07673\n",
      "\tClass 3: 0.07217 ± 0.04485\n",
      "Mean recall: 0.5269 ± 0.05381\n",
      "\tClass 1: 0.42557 ± 0.15466\n",
      "\tClass 2: 0.76927 ± 0.09785\n",
      "\tClass 3: 0.0341 ± 0.03568\n",
      "Mean f1_score: 0.46031 ± 0.07918\n",
      "\tClass 1: 0.37994 ± 0.12718\n",
      "\tClass 2: 0.66231 ± 0.08904\n",
      "\tClass 3: 0.04225 ± 0.03938\n",
      "Training ANN with topology: [16]\n",
      "Mean accuracy: 0.63504 ± 0.05098\n",
      "\tClass 1: 0.58392 ± 0.08432\n",
      "\tClass 2: 0.62649 ± 0.04824\n",
      "\tClass 3: 0.75031 ± 0.01248\n",
      "Mean precision: 0.45757 ± 0.04323\n",
      "\tClass 1: 0.40101 ± 0.08343\n",
      "\tClass 2: 0.62315 ± 0.0512\n",
      "\tClass 3: 0.09812 ± 0.02221\n",
      "Mean recall: 0.48036 ± 0.0681\n",
      "\tClass 1: 0.46347 ± 0.0851\n",
      "\tClass 2: 0.64305 ± 0.14884\n",
      "\tClass 3: 0.05796 ± 0.02214\n",
      "Mean f1_score: 0.45506 ± 0.05797\n",
      "\tClass 1: 0.4148 ± 0.06289\n",
      "\tClass 2: 0.61984 ± 0.08681\n",
      "\tClass 3: 0.0687 ± 0.02134\n",
      "Training ANN with topology: [32]\n",
      "Mean accuracy: 0.64294 ± 0.04618\n",
      "\tClass 1: 0.62236 ± 0.05314\n",
      "\tClass 2: 0.61649 ± 0.06055\n",
      "\tClass 3: 0.75345 ± 0.0201\n",
      "Mean precision: 0.4671 ± 0.0464\n",
      "\tClass 1: 0.43324 ± 0.06315\n",
      "\tClass 2: 0.60044 ± 0.05451\n",
      "\tClass 3: 0.15687 ± 0.05088\n",
      "Mean recall: 0.49615 ± 0.0569\n",
      "\tClass 1: 0.42286 ± 0.09116\n",
      "\tClass 2: 0.6858 ± 0.11567\n",
      "\tClass 3: 0.09982 ± 0.06121\n",
      "Mean f1_score: 0.46673 ± 0.05639\n",
      "\tClass 1: 0.40978 ± 0.06601\n",
      "\tClass 2: 0.6315 ± 0.08182\n",
      "\tClass 3: 0.11036 ± 0.05768\n",
      "Training ANN with topology: [64]\n",
      "Mean accuracy: 0.6325 ± 0.02148\n",
      "\tClass 1: 0.6022 ± 0.0365\n",
      "\tClass 2: 0.60143 ± 0.02602\n",
      "\tClass 3: 0.77323 ± 0.00934\n",
      "Mean precision: 0.44825 ± 0.02873\n",
      "\tClass 1: 0.39295 ± 0.05905\n",
      "\tClass 2: 0.59437 ± 0.03221\n",
      "\tClass 3: 0.14078 ± 0.06365\n",
      "Mean recall: 0.48843 ± 0.028\n",
      "\tClass 1: 0.37994 ± 0.08353\n",
      "\tClass 2: 0.71582 ± 0.06787\n",
      "\tClass 3: 0.04989 ± 0.0236\n",
      "Mean f1_score: 0.44209 ± 0.0223\n",
      "\tClass 1: 0.35599 ± 0.04692\n",
      "\tClass 2: 0.63521 ± 0.03115\n",
      "\tClass 3: 0.05889 ± 0.01836\n",
      "Training ANN with topology: [16, 16]\n",
      "Mean accuracy: 0.62109 ± 0.02467\n",
      "\tClass 1: 0.61992 ± 0.03829\n",
      "\tClass 2: 0.55435 ± 0.03559\n",
      "\tClass 3: 0.80887 ± 0.00961\n",
      "Mean precision: 0.38288 ± 0.03693\n",
      "\tClass 1: 0.32292 ± 0.05868\n",
      "\tClass 2: 0.54441 ± 0.03126\n",
      "\tClass 3: 0.04072 ± 0.04449\n",
      "Mean recall: 0.49157 ± 0.02941\n",
      "\tClass 1: 0.30686 ± 0.12653\n",
      "\tClass 2: 0.78174 ± 0.08956\n",
      "\tClass 3: 0.01472 ± 0.01203\n",
      "Mean f1_score: 0.40758 ± 0.02911\n",
      "\tClass 1: 0.28471 ± 0.07186\n",
      "\tClass 2: 0.62707 ± 0.03854\n",
      "\tClass 3: 0.0168 ± 0.01242\n",
      "Training ANN with topology: [32, 16]\n",
      "Mean accuracy: 0.66219 ± 0.04076\n",
      "\tClass 1: 0.66794 ± 0.05529\n",
      "\tClass 2: 0.61129 ± 0.05846\n",
      "\tClass 3: 0.79339 ± 0.01802\n",
      "Mean precision: 0.46358 ± 0.06073\n",
      "\tClass 1: 0.48318 ± 0.11877\n",
      "\tClass 2: 0.59365 ± 0.05204\n",
      "\tClass 3: 0.06651 ± 0.04961\n",
      "Mean recall: 0.53631 ± 0.04613\n",
      "\tClass 1: 0.39876 ± 0.09433\n",
      "\tClass 2: 0.80902 ± 0.04817\n",
      "\tClass 3: 0.0238 ± 0.01613\n",
      "Mean f1_score: 0.4701 ± 0.05717\n",
      "\tClass 1: 0.40028 ± 0.10379\n",
      "\tClass 2: 0.67314 ± 0.04429\n",
      "\tClass 3: 0.03014 ± 0.0209\n",
      "Training ANN with topology: [32, 32]\n",
      "Mean accuracy: 0.65077 ± 0.00591\n",
      "\tClass 1: 0.64979 ± 0.01625\n",
      "\tClass 2: 0.59871 ± 0.01531\n",
      "\tClass 3: 0.79741 ± 0.01044\n",
      "Mean precision: 0.43987 ± 0.01067\n",
      "\tClass 1: 0.43496 ± 0.03863\n",
      "\tClass 2: 0.58286 ± 0.02129\n",
      "\tClass 3: 0.0509 ± 0.03016\n",
      "Mean recall: 0.52296 ± 0.00886\n",
      "\tClass 1: 0.38032 ± 0.08441\n",
      "\tClass 2: 0.7954 ± 0.05595\n",
      "\tClass 3: 0.02019 ± 0.01881\n",
      "Mean f1_score: 0.45186 ± 0.01385\n",
      "\tClass 1: 0.3644 ± 0.05289\n",
      "\tClass 2: 0.66207 ± 0.01126\n",
      "\tClass 3: 0.02348 ± 0.01597\n",
      "Training ANN with topology: [64, 64]\n",
      "Mean accuracy: 0.6489 ± 0.03542\n",
      "\tClass 1: 0.64676 ± 0.02659\n",
      "\tClass 2: 0.5966 ± 0.06223\n",
      "\tClass 3: 0.79818 ± 0.02071\n",
      "Mean precision: 0.45638 ± 0.05782\n",
      "\tClass 1: 0.46455 ± 0.07295\n",
      "\tClass 2: 0.58825 ± 0.05659\n",
      "\tClass 3: 0.07488 ± 0.06461\n",
      "Mean recall: 0.52077 ± 0.03382\n",
      "\tClass 1: 0.3558 ± 0.1092\n",
      "\tClass 2: 0.80284 ± 0.01914\n",
      "\tClass 3: 0.03116 ± 0.03117\n",
      "Mean f1_score: 0.4393 ± 0.06265\n",
      "\tClass 1: 0.32416 ± 0.11516\n",
      "\tClass 2: 0.65719 ± 0.0386\n",
      "\tClass 3: 0.03912 ± 0.03662\n"
     ]
    }
   ],
   "source": [
    "# Set the random seed for reproducibility\n",
    "Random.seed!(42)\n",
    "\n",
    "topologies = [ [64, 32], [16], [32], [64], [16, 16], [32, 16], [32, 32], [64, 64]]\n",
    "\n",
    "smote_percentage = Dict(\"Enrolled\" => 300, \"Graduate\" => 100, \"Dropout\" => 100)\n",
    "\n",
    "general_results_ann = []\n",
    "class_results_ann = []\n",
    "\n",
    "for topology in topologies\n",
    "  hyperparameters = Dict(\n",
    "    \"topology\" => topology,\n",
    "    \"learningRate\" => 0.01,\n",
    "    \"maxEpochs\" => 100,\n",
    "    \"repetitionsTraining\" => 10,\n",
    "    \"validationRatio\" => 0.15,\n",
    "    \"maxEpochsVal\" => 10,\n",
    "    \"minLoss\" => 0.0001\n",
    "  )\n",
    "\n",
    "  println(\"Training ANN with topology: \", topology)\n",
    "\n",
    "  gr, cr = modelCrossValidation(\n",
    "    :ANN,\n",
    "    hyperparameters,\n",
    "    inputs,\n",
    "    targets,\n",
    "    fold_indices;\n",
    "    metricsToSave=metrics_to_save,\n",
    "    normalizationType=:zeroMean,\n",
    "    applyPCA=true,\n",
    "    pcaComponents=0.95,\n",
    "    applySmote=true,\n",
    "    smotePercentages=smote_percentage,\n",
    "    smoteNeighbors=k,\n",
    "    verbose=false\n",
    "  )\n",
    "\n",
    "  push!(general_results_ann, gr)\n",
    "  push!(class_results_ann, cr)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ScikitLearn ANN\n",
    "\n",
    "We will use the MLPClassifier from ScikitLearn to train the ANN models. The hyperparameters used in the models are the same as in the previous ANN implementation:\n",
    "\n",
    "We trained 8 models, 3 with one hidden layer and 5 with two hidden layers. The used topology for the hidden layers are:\n",
    "\n",
    "- **One hidden layer**:\n",
    "  - 16 neurons\n",
    "  - 32 neurons\n",
    "  - 64 neurons\n",
    "- **Two hidden layers**:\n",
    "  - (16, 16) neurons\n",
    "  - (32, 16) neurons\n",
    "  - (32, 32) neurons\n",
    "  - (64, 32) neurons\n",
    "  - (64, 64) neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ANN with topology: [16]\n",
      "Mean accuracy: 0.75216"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markel/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ± 0.02319\n",
      "\tClass 1: 0.78176 ± 0.03157\n",
      "\tClass 2: 0.70719 ± 0.0751\n",
      "\tClass 3: 0.73961 ± 0.0565\n",
      "Mean precision: 0.72335 ± 0.01168\n",
      "\tClass 1: 0.76048 ± 0.08484\n",
      "\tClass 2: 0.49098 ± 0.1725\n",
      "\tClass 3: 0.68027 ± 0.20461\n",
      "Mean recall: 0.61428 ± 0.03788\n",
      "\tClass 1: 0.60217 ± 0.05112\n",
      "\tClass 2: 0.67842 ± 0.06936\n",
      "\tClass 3: 0.60225 ± 0.06697\n",
      "Mean f1_score: 0.64065 ± 0.03297\n",
      "\tClass 1: 0.65984 ± 0.03476\n",
      "\tClass 2: 0.53153 ± 0.09351\n",
      "\tClass 3: 0.60854 ± 0.09976\n",
      "Training ANN with topology: [32]\n",
      "Mean accuracy: 0.76077 ± 0.01534\n",
      "\tClass 1: 0.78775 ± 0.03401\n",
      "\tClass 2: 0.71821 ± 0.06984\n",
      "\tClass 3: 0.74596 ± 0.03613\n",
      "Mean precision: 0.7264 ± 0.01239\n",
      "\tClass 1: 0.75992 ± 0.07409\n",
      "\tClass 2: 0.50448 ± 0.18979\n",
      "\tClass 3: 0.67788 ± 0.18411\n",
      "Mean recall: 0.62596 ± 0.0275\n",
      "\tClass 1: 0.59994 ± 0.05341\n",
      "\tClass 2: 0.66048 ± 0.06378\n",
      "\tClass 3: 0.63215 ± 0.04713\n",
      "Mean f1_score: 0.65152 ± 0.02196\n",
      "\tClass 1: 0.65748 ± 0.02786\n",
      "\tClass 2: 0.53508 ± 0.10111\n",
      "\tClass 3: 0.62837 ± 0.08874\n",
      "Training ANN with topology: [64]\n",
      "Mean accuracy: 0.76486"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markel/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/markel/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ± 0.00688\n",
      "\tClass 1: 0.77469 ± 0.02775\n",
      "\tClass 2: 0.73657 ± 0.0451\n",
      "\tClass 3: 0.75897 ± 0.03552\n",
      "Mean precision: 0.71618 ± 0.01143\n",
      "\tClass 1: 0.74495 ± 0.07911\n",
      "\tClass 2: 0.51116 ± 0.16486\n",
      "\tClass 3: 0.66479 ± 0.18691\n",
      "Mean recall: 0.63511 ± 0.01307\n",
      "\tClass 1: 0.62757 ± 0.05998\n",
      "\tClass 2: 0.63835 ± 0.02899\n",
      "\tClass 3: 0.63038 ± 0.01824\n",
      "Mean f1_score: 0.65724 ± 0.00989\n",
      "\tClass 1: 0.668 ± 0.04966\n",
      "\tClass 2: 0.53911 ± 0.0902\n",
      "\tClass 3: 0.62696 ± 0.10236\n",
      "Training ANN with topology: [16, 16]\n",
      "Mean accuracy: 0.75418 ± 0.02539\n",
      "\tClass 1: 0.76089 ± 0.0557\n",
      "\tClass 2: 0.73787 ± 0.03385\n",
      "\tClass 3: 0.73794 ± 0.05118\n",
      "Mean precision: 0.71801 ± 0.00895\n",
      "\tClass 1: 0.70362 ± 0.14261\n",
      "\tClass 2: 0.54732 ± 0.12888\n",
      "\tClass 3: 0.66829 ± 0.20858\n",
      "Mean recall: 0.61835 ± 0.04307\n",
      "\tClass 1: 0.65319 ± 0.04056\n",
      "\tClass 2: 0.61436 ± 0.0214\n",
      "\tClass 3: 0.60767 ± 0.07612\n",
      "Mean f1_score: 0.64267 ± 0.03751\n",
      "\tClass 1: 0.65265 ± 0.09094\n",
      "\tClass 2: 0.54361 ± 0.06292\n",
      "\tClass 3: 0.60484 ± 0.10349\n",
      "Training ANN with topology: [32, 16]\n",
      "Mean accuracy: 0.7588 ± 0.01746\n",
      "\tClass 1: 0.77181 ± 0.02325\n",
      "\tClass 2: 0.72927 ± 0.04849\n",
      "\tClass 3: 0.75058 ± 0.04225\n",
      "Mean precision: 0.71469 ± 0.01228\n",
      "\tClass 1: 0.72602 ± 0.10401\n",
      "\tClass 2: 0.48459 ± 0.17129\n",
      "\tClass 3: 0.70099 ± 0.20645\n",
      "Mean recall: 0.62583 ± 0.03063\n",
      "\tClass 1: 0.64368 ± 0.04405\n",
      "\tClass 2: 0.6338 ± 0.01821\n",
      "\tClass 3: 0.60437 ± 0.03393\n",
      "Mean f1_score: 0.64913 ± 0.02448\n",
      "\tClass 1: 0.66671 ± 0.08085\n",
      "\tClass 2: 0.51808 ± 0.09629\n",
      "\tClass 3: 0.63005 ± 0.1184\n",
      "Training ANN with topology: [32, 32]\n",
      "Mean accuracy: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markel/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/markel/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76177 ± 0.01935\n",
      "\tClass 1: 0.79173 ± 0.03008\n",
      "\tClass 2: 0.71638 ± 0.0695\n",
      "\tClass 3: 0.75006 ± 0.04349\n",
      "Mean precision: 0.72551 ± 0.0108\n",
      "\tClass 1: 0.78191 ± 0.05543\n",
      "\tClass 2: 0.48599 ± 0.17368\n",
      "\tClass 3: 0.67607 ± 0.19202\n",
      "Mean recall: 0.62909 ± 0.03279\n",
      "\tClass 1: 0.62367 ± 0.04922\n",
      "\tClass 2: 0.6525 ± 0.05636\n",
      "\tClass 3: 0.62348 ± 0.05625\n",
      "Mean f1_score: 0.65379 ± 0.02656\n",
      "\tClass 1: 0.68393 ± 0.03194\n",
      "\tClass 2: 0.52257 ± 0.09139\n",
      "\tClass 3: 0.62376 ± 0.09856\n",
      "Training ANN with topology: [64, 32]\n",
      "Mean accuracy: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markel/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/markel/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/markel/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/markel/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75965 ± 0.01033\n",
      "\tClass 1: 0.78418 ± 0.04086\n",
      "\tClass 2: 0.73084 ± 0.06108\n",
      "\tClass 3: 0.74034 ± 0.03589\n",
      "Mean precision: 0.71859 ± 0.01083\n",
      "\tClass 1: 0.74021 ± 0.09591\n",
      "\tClass 2: 0.54293 ± 0.16919\n",
      "\tClass 3: 0.63612 ± 0.20661\n",
      "Mean recall: 0.62768 ± 0.0193\n",
      "\tClass 1: 0.63518 ± 0.03328\n",
      "\tClass 2: 0.64665 ± 0.04331\n",
      "\tClass 3: 0.61514 ± 0.03226\n",
      "Mean f1_score: 0.65193 ± 0.01485\n",
      "\tClass 1: 0.67246 ± 0.05289\n",
      "\tClass 2: 0.55779 ± 0.09673\n",
      "\tClass 3: 0.59632 ± 0.10356\n",
      "Training ANN with topology: [64, 64]\n",
      "Mean accuracy: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markel/.julia/conda/3/x86_64/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75824 ± 0.02448\n",
      "\tClass 1: 0.77921 ± 0.02841\n",
      "\tClass 2: 0.73094 ± 0.06898\n",
      "\tClass 3: 0.73929 ± 0.05156\n",
      "Mean precision: 0.71985 ± 0.01846\n",
      "\tClass 1: 0.71991 ± 0.08259\n",
      "\tClass 2: 0.54764 ± 0.16469\n",
      "\tClass 3: 0.66039 ± 0.20999\n",
      "Mean recall: 0.62472 ± 0.03985\n",
      "\tClass 1: 0.62754 ± 0.04751\n",
      "\tClass 2: 0.64454 ± 0.04674\n",
      "\tClass 3: 0.61555 ± 0.05833\n",
      "Mean f1_score: 0.64889 ± 0.03398\n",
      "\tClass 1: 0.65369 ± 0.03327\n",
      "\tClass 2: 0.55636 ± 0.09558\n",
      "\tClass 3: 0.60764 ± 0.10709\n"
     ]
    }
   ],
   "source": [
    "# Set the random seed for reproducibility\n",
    "Random.seed!(42)\n",
    "\n",
    "topologies = [[16], [32], [64], [16, 16], [32, 16], [32, 32], [64, 32], [64, 64]]\n",
    "\n",
    "general_results_scikit_ann = []\n",
    "class_results_scikit_ann = []\n",
    "\n",
    "for topology in topologies\n",
    "  hyperparameters = Dict(\n",
    "    :hidden_layer_sizes => topology,\n",
    "    :learning_rate_init => 0.01,\n",
    "    :max_iter => 100,\n",
    "    :early_stopping => true,\n",
    "    :tol => 0,\n",
    "    :validation_fraction => 0.15,\n",
    "    :n_iter_no_change => 10,\n",
    "    :epsilon => 0.0001,\n",
    "    :repetitionsTraining => 10\n",
    "  )\n",
    "\n",
    "  println(\"Training ANN with topology: \", topology)\n",
    "\n",
    "  gr, cr = modelCrossValidation(\n",
    "    :scikit_ANN,\n",
    "    hyperparameters,\n",
    "    inputs,\n",
    "    targets,\n",
    "    fold_indices;\n",
    "    metricsToSave=metrics_to_save,\n",
    "    normalizationType=:zeroMean,\n",
    "    applyPCA=true,\n",
    "    pcaComponents=0.95,\n",
    "    applySmote=true,\n",
    "    smotePercentages=smote_percentage,\n",
    "    smoteNeighbors=k,\n",
    "    verbose=false\n",
    "  )\n",
    "\n",
    "  push!(general_results_scikit_ann, gr)\n",
    "  push!(class_results_scikit_ann, cr)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "\n",
    "The Decision Tree model will be trained with the following hyperparameters:\n",
    "\n",
    "- Maximum depth of the tree $\\in \\{3, 5, 10, 15, 20, \\text{nothing}\\}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DT model with max_depth: 3\n",
      "Mean accuracy: 0.68289 ± 0.0509\n",
      "\tClass 1: 0.71131 ± 0.0564\n",
      "\tClass 2: 0.64725 ± 0.15231\n",
      "\tClass 3: 0.67724 ± 0.08727\n",
      "Mean precision: 0.63093 ± 0.02223\n",
      "\tClass 1: 0.6256 ± 0.2113\n",
      "\tClass 2: 0.4554 ± 0.3221\n",
      "\tClass 3: 0.61786 ± 0.18871\n",
      "Mean recall: 0.51789 ± 0.09049\n",
      "\tClass 1: 0.59017 ± 0.21087\n",
      "\tClass 2: 0.51024 ± 0.12778\n",
      "\tClass 3: 0.408 ± 0.13039\n",
      "Mean f1_score: 0.5344 ± 0.07349\n",
      "\tClass 1: 0.56803 ± 0.15457\n",
      "\tClass 2: 0.41391 ± 0.14491\n",
      "\tClass 3: 0.4846 ± 0.14356\n",
      "Training DT model with max_depth: 5\n",
      "Mean accuracy: 0.69532 ± 0.03691\n",
      "\tClass 1: 0.7145 ± 0.06762\n",
      "\tClass 2: 0.66554 ± 0.09342\n",
      "\tClass 3: 0.68468 ± 0.09599\n",
      "Mean precision: 0.65031 ± 0.03044\n",
      "\tClass 1: 0.55628 ± 0.26307\n",
      "\tClass 2: 0.61799 ± 0.22934\n",
      "\tClass 3: 0.56997 ± 0.29323\n",
      "Mean recall: 0.53236 ± 0.05737\n",
      "\tClass 1: 0.5526 ± 0.08853\n",
      "\tClass 2: 0.58244 ± 0.11997\n",
      "\tClass 3: 0.45602 ± 0.10096\n",
      "Mean f1_score: 0.55564 ± 0.05432\n",
      "\tClass 1: 0.52045 ± 0.14676\n",
      "\tClass 2: 0.565 ± 0.1555\n",
      "\tClass 3: 0.45218 ± 0.11016\n",
      "Training DT model with max_depth: 10\n",
      "Mean accuracy: 0.70009 ± 0.0284\n",
      "\tClass 1: 0.69193 ± 0.07201\n",
      "\tClass 2: 0.71723 ± 0.04085\n",
      "\tClass 3: 0.69034 ± 0.04717\n",
      "Mean precision: 0.6134 ± 0.01918\n",
      "\tClass 1: 0.58502 ± 0.21125\n",
      "\tClass 2: 0.61217 ± 0.19305\n",
      "\tClass 3: 0.43604 ± 0.19219\n",
      "Mean recall: 0.54975 ± 0.04599\n",
      "\tClass 1: 0.56809 ± 0.04861\n",
      "\tClass 2: 0.53835 ± 0.07613\n",
      "\tClass 3: 0.50459 ± 0.02513\n",
      "Mean f1_score: 0.56942 ± 0.03925\n",
      "\tClass 1: 0.56107 ± 0.14825\n",
      "\tClass 2: 0.56344 ± 0.13229\n",
      "\tClass 3: 0.4497 ± 0.10541\n",
      "Training DT model with max_depth: 15\n",
      "Mean accuracy: 0.6821 ± 0.0281\n",
      "\tClass 1: 0.69709 ± 0.02286\n",
      "\tClass 2: 0.66438 ± 0.05358\n",
      "\tClass 3: 0.6788 ± 0.07462\n",
      "Mean precision: 0.59656 ± 0.02655\n",
      "\tClass 1: 0.57517 ± 0.18335\n",
      "\tClass 2: 0.50699 ± 0.23883\n",
      "\tClass 3: 0.49688 ± 0.22511\n",
      "Mean recall: 0.52014 ± 0.04382\n",
      "\tClass 1: 0.52965 ± 0.07987\n",
      "\tClass 2: 0.50085 ± 0.04847\n",
      "\tClass 3: 0.50935 ± 0.03929\n",
      "Mean f1_score: 0.54207 ± 0.04045\n",
      "\tClass 1: 0.54091 ± 0.12931\n",
      "\tClass 2: 0.47952 ± 0.14434\n",
      "\tClass 3: 0.47554 ± 0.12568\n",
      "Training DT model with max_depth: 20\n",
      "Mean accuracy: 0.68589 ± 0.02342\n",
      "\tClass 1: 0.69802 ± 0.0524\n",
      "\tClass 2: 0.67562 ± 0.03002\n",
      "\tClass 3: 0.67795 ± 0.07123\n",
      "Mean precision: 0.60126 ± 0.02049\n",
      "\tClass 1: 0.59015 ± 0.18325\n",
      "\tClass 2: 0.5077 ± 0.23305\n",
      "\tClass 3: 0.48961 ± 0.23655\n",
      "Mean recall: 0.5258 ± 0.03643\n",
      "\tClass 1: 0.5175 ± 0.0624\n",
      "\tClass 2: 0.51789 ± 0.04783\n",
      "\tClass 3: 0.51735 ± 0.03383\n",
      "Mean f1_score: 0.54846 ± 0.03414\n",
      "\tClass 1: 0.54004 ± 0.11757\n",
      "\tClass 2: 0.49325 ± 0.1476\n",
      "\tClass 3: 0.47943 ± 0.14851\n",
      "Training DT model with max_depth: nothing\n",
      "Mean accuracy: 0.68862 ± 0.02375\n",
      "\tClass 1: 0.68489 ± 0.04999\n",
      "\tClass 2: 0.69937 ± 0.037\n",
      "\tClass 3: 0.68129 ± 0.0691\n",
      "Mean precision: 0.60151 ± 0.0184\n",
      "\tClass 1: 0.5206 ± 0.23585\n",
      "\tClass 2: 0.49609 ± 0.19041\n",
      "\tClass 3: 0.57899 ± 0.20926\n",
      "Mean recall: 0.53278 ± 0.04053\n",
      "\tClass 1: 0.53714 ± 0.06446\n",
      "\tClass 2: 0.51424 ± 0.06748\n",
      "\tClass 3: 0.5222 ± 0.04485\n",
      "Mean f1_score: 0.55314 ± 0.03459\n",
      "\tClass 1: 0.50965 ± 0.1554\n",
      "\tClass 2: 0.48772 ± 0.11658\n",
      "\tClass 3: 0.53358 ± 0.13543\n"
     ]
    }
   ],
   "source": [
    "max_depths = [3, 5, 10, 15, 20, nothing]\n",
    "\n",
    "general_results_dt = []\n",
    "class_results_dt = []\n",
    "\n",
    "for max_depth in max_depths\n",
    "  hyperparameters = Dict(\n",
    "    :max_depth => max_depth,\n",
    "    :criterion => \"gini\",\n",
    "    :min_samples_split => 2,\n",
    "  )\n",
    "\n",
    "  println(\"Training DT model with max_depth: \", max_depth)\n",
    "\n",
    "  gr, ct = modelCrossValidation(\n",
    "    :DT,\n",
    "    hyperparameters,\n",
    "    inputs,\n",
    "    targets,\n",
    "    fold_indices;\n",
    "    metricsToSave=metrics_to_save,\n",
    "    normalizationType=:zeroMean,\n",
    "    applyPCA=true,\n",
    "    pcaComponents=0.95,\n",
    "    applySmote=true,\n",
    "    smotePercentages=smote_percentage,\n",
    "    smoteNeighbors=k,\n",
    "    verbose=false\n",
    "  )\n",
    "\n",
    "  push!(general_results_dt, gr)\n",
    "  push!(class_results_dt, ct)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n",
    "\n",
    "The SVM model will be trained with all the possible combinations of the following hyperparameters:\n",
    "\n",
    "- Kernel $\\in \\{\\text{linear}, \\text{poly}, \\text{rbf}, \\text{sigmoid}\\}$\n",
    "- C $\\in \\{0.1, 1, 10\\}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM model with kernel: linear and C: 0.1\n",
      "Mean accuracy: 0.77448 ± 0.01921\n",
      "\tClass 1: 0.78683 ± 0.02724\n",
      "\tClass 2: 0.74802 ± 0.06558\n",
      "\tClass 3: 0.7708 ± 0.04208\n",
      "Mean precision: 0.71598 ± 0.01267\n",
      "\tClass 1: 0.7093 ± 0.1815\n",
      "\tClass 2: 0.59796 ± 0.25739\n",
      "\tClass 3: 0.62383 ± 0.23252\n",
      "Mean recall: 0.65282 ± 0.03295\n",
      "\tClass 1: 0.66226 ± 0.05655\n",
      "\tClass 2: 0.6722 ± 0.07187\n",
      "\tClass 3: 0.58959 ± 0.03386\n",
      "Mean f1_score: 0.67091 ± 0.02527\n",
      "\tClass 1: 0.67382 ± 0.11197\n",
      "\tClass 2: 0.61198 ± 0.17808\n",
      "\tClass 3: 0.58759 ± 0.12233\n",
      "Training SVM model with kernel: linear and C: 1.0\n",
      "Mean accuracy: 0.77743 ± 0.02491\n",
      "\tClass 1: 0.79542 ± 0.0258\n",
      "\tClass 2: 0.74757 ± 0.07241\n",
      "\tClass 3: 0.77126 ± 0.03852\n",
      "Mean precision: 0.71798 ± 0.01118\n",
      "\tClass 1: 0.69394 ± 0.17251\n",
      "\tClass 2: 0.51551 ± 0.24773\n",
      "\tClass 3: 0.72964 ± 0.1881\n",
      "Mean recall: 0.65712 ± 0.04162\n",
      "\tClass 1: 0.64698 ± 0.04412\n",
      "\tClass 2: 0.64493 ± 0.08425\n",
      "\tClass 3: 0.63965 ± 0.08549\n",
      "Mean f1_score: 0.6745 ± 0.03272\n",
      "\tClass 1: 0.65991 ± 0.10319\n",
      "\tClass 2: 0.55455 ± 0.17735\n",
      "\tClass 3: 0.66915 ± 0.11712\n",
      "Training SVM model with kernel: linear and C: 10.0\n",
      "Mean accuracy: 0.77699 ± 0.01834\n",
      "\tClass 1: 0.79384 ± 0.02615\n",
      "\tClass 2: 0.7566 ± 0.05794\n",
      "\tClass 3: 0.76515 ± 0.0292\n",
      "Mean precision: 0.71568 ± 0.00484\n",
      "\tClass 1: 0.68399 ± 0.17443\n",
      "\tClass 2: 0.61155 ± 0.2433\n",
      "\tClass 3: 0.63828 ± 0.23736\n",
      "Mean recall: 0.65779 ± 0.03152\n",
      "\tClass 1: 0.6483 ± 0.05016\n",
      "\tClass 2: 0.67683 ± 0.0584\n",
      "\tClass 3: 0.61646 ± 0.0552\n",
      "Mean f1_score: 0.67437 ± 0.02426\n",
      "\tClass 1: 0.6578 ± 0.11333\n",
      "\tClass 2: 0.62173 ± 0.16115\n",
      "\tClass 3: 0.60821 ± 0.133\n",
      "Training SVM model with kernel: poly and C: 0.1\n",
      "Mean accuracy: 0.62476 ± 0.0162\n",
      "\tClass 1: 0.59326 ± 0.18437\n",
      "\tClass 2: 0.60094 ± 0.17124\n",
      "\tClass 3: 0.62771 ± 0.08937\n",
      "Mean precision: 0.68096 ± 0.01745\n",
      "\tClass 1: 0.47498 ± 0.33662\n",
      "\tClass 2: 0.55761 ± 0.30574\n",
      "\tClass 3: 0.771 ± 0.04062\n",
      "Mean recall: 0.41095 ± 0.02654\n",
      "\tClass 1: 0.68233 ± 0.22507\n",
      "\tClass 2: 0.54589 ± 0.29769\n",
      "\tClass 3: 0.29046 ± 0.08502\n",
      "Mean f1_score: 0.42719 ± 0.03479\n",
      "\tClass 1: 0.44631 ± 0.11792\n",
      "\tClass 2: 0.42121 ± 0.11831\n",
      "\tClass 3: 0.41738 ± 0.09494\n",
      "Training SVM model with kernel: poly and C: 1.0\n",
      "Mean accuracy: 0.75917 ± 0.01841\n",
      "\tClass 1: 0.76626 ± 0.05925\n",
      "\tClass 2: 0.73085 ± 0.06791\n",
      "\tClass 3: 0.75383 ± 0.06356\n",
      "Mean precision: 0.72798 ± 0.01523\n",
      "\tClass 1: 0.71356 ± 0.225\n",
      "\tClass 2: 0.61406 ± 0.26672\n",
      "\tClass 3: 0.6365 ± 0.27598\n",
      "Mean recall: 0.62547 ± 0.0303\n",
      "\tClass 1: 0.63342 ± 0.08813\n",
      "\tClass 2: 0.66337 ± 0.08582\n",
      "\tClass 3: 0.59127 ± 0.06393\n",
      "Mean f1_score: 0.64981 ± 0.02471\n",
      "\tClass 1: 0.64578 ± 0.13123\n",
      "\tClass 2: 0.59773 ± 0.14337\n",
      "\tClass 3: 0.57466 ± 0.12058\n",
      "Training SVM model with kernel: poly and C: 10.0\n",
      "Mean accuracy: 0.76673 ± 0.01113\n",
      "\tClass 1: 0.77713 ± 0.04748\n",
      "\tClass 2: 0.72335 ± 0.03144\n",
      "\tClass 3: 0.78165 ± 0.03709\n",
      "Mean precision: 0.71083 ± 0.00706\n",
      "\tClass 1: 0.6822 ± 0.20181\n",
      "\tClass 2: 0.43353 ± 0.19717\n",
      "\tClass 3: 0.80692 ± 0.02348\n",
      "Mean recall: 0.64107 ± 0.01966\n",
      "\tClass 1: 0.61298 ± 0.06535\n",
      "\tClass 2: 0.64386 ± 0.04616\n",
      "\tClass 3: 0.63373 ± 0.08248\n",
      "Mean f1_score: 0.66024 ± 0.01414\n",
      "\tClass 1: 0.62987 ± 0.12369\n",
      "\tClass 2: 0.50358 ± 0.1296\n",
      "\tClass 3: 0.70732 ± 0.05162\n",
      "Training SVM model with kernel: rbf and C: 0.1\n",
      "Mean accuracy: 0.75379 ± 0.01847\n",
      "\tClass 1: 0.77552 ± 0.05106\n",
      "\tClass 2: 0.70644 ± 0.07902\n",
      "\tClass 3: 0.74728 ± 0.04409\n",
      "Mean precision: 0.72762 ± 0.01737\n",
      "\tClass 1: 0.73603 ± 0.22995\n",
      "\tClass 2: 0.50503 ± 0.2669\n",
      "\tClass 3: 0.7201 ± 0.21664\n",
      "Mean recall: 0.61462 ± 0.03134\n",
      "\tClass 1: 0.57181 ± 0.11372\n",
      "\tClass 2: 0.67444 ± 0.11315\n",
      "\tClass 3: 0.61073 ± 0.10875\n",
      "Mean f1_score: 0.63803 ± 0.02424\n",
      "\tClass 1: 0.61103 ± 0.10607\n",
      "\tClass 2: 0.53219 ± 0.1437\n",
      "\tClass 3: 0.63612 ± 0.12506\n",
      "Training SVM model with kernel: rbf and C: 1.0\n",
      "Mean accuracy: 0.78347 ± 0.00965\n",
      "\tClass 1: 0.78818 ± 0.03715\n",
      "\tClass 2: 0.76496 ± 0.05144\n",
      "\tClass 3: 0.77597 ± 0.05505\n",
      "Mean precision: 0.74002 ± 0.00852\n",
      "\tClass 1: 0.72913 ± 0.20054\n",
      "\tClass 2: 0.62895 ± 0.25225\n",
      "\tClass 3: 0.65167 ± 0.26699\n",
      "Mean recall: 0.66456 ± 0.01572\n",
      "\tClass 1: 0.64676 ± 0.06364\n",
      "\tClass 2: 0.69348 ± 0.0547\n",
      "\tClass 3: 0.63511 ± 0.05225\n",
      "Mean f1_score: 0.6843 ± 0.01246\n",
      "\tClass 1: 0.6709 ± 0.11827\n",
      "\tClass 2: 0.63502 ± 0.15613\n",
      "\tClass 3: 0.61119 ± 0.13021\n",
      "Training SVM model with kernel: rbf and C: 10.0\n",
      "Mean accuracy: 0.77165 ± 0.01069\n",
      "\tClass 1: 0.7909 ± 0.01891\n",
      "\tClass 2: 0.7627 ± 0.05542\n",
      "\tClass 3: 0.74388 ± 0.02512\n",
      "Mean precision: 0.70684 ± 0.0115\n",
      "\tClass 1: 0.77106 ± 0.04877\n",
      "\tClass 2: 0.59094 ± 0.23603\n",
      "\tClass 3: 0.53841 ± 0.25681\n",
      "Mean recall: 0.64874 ± 0.02007\n",
      "\tClass 1: 0.64002 ± 0.06009\n",
      "\tClass 2: 0.6349 ± 0.04313\n",
      "\tClass 3: 0.62696 ± 0.05235\n",
      "Mean f1_score: 0.66716 ± 0.01718\n",
      "\tClass 1: 0.69889 ± 0.05315\n",
      "\tClass 2: 0.59625 ± 0.15647\n",
      "\tClass 3: 0.56156 ± 0.16663\n",
      "Training SVM model with kernel: sigmoid and C: 0.1\n",
      "Mean accuracy: 0.76059 ± 0.03126\n",
      "\tClass 1: 0.78727 ± 0.03786\n",
      "\tClass 2: 0.72679 ± 0.08615\n",
      "\tClass 3: 0.7491 ± 0.05306\n",
      "Mean precision: 0.71376 ± 0.00698\n",
      "\tClass 1: 0.71968 ± 0.1958\n",
      "\tClass 2: 0.51019 ± 0.25631\n",
      "\tClass 3: 0.70469 ± 0.19914\n",
      "Mean recall: 0.63158 ± 0.0514\n",
      "\tClass 1: 0.59576 ± 0.07168\n",
      "\tClass 2: 0.65239 ± 0.09354\n",
      "\tClass 3: 0.62578 ± 0.13182\n",
      "Mean f1_score: 0.65002 ± 0.04212\n",
      "\tClass 1: 0.63411 ± 0.09952\n",
      "\tClass 2: 0.5418 ± 0.1629\n",
      "\tClass 3: 0.64143 ± 0.13305\n",
      "Training SVM model with kernel: sigmoid and C: 1.0\n",
      "Mean accuracy: 0.73564 ± 0.01887\n",
      "\tClass 1: 0.76762 ± 0.01953\n",
      "\tClass 2: 0.69557 ± 0.05661\n",
      "\tClass 3: 0.72582 ± 0.03624\n",
      "Mean precision: 0.66973 ± 0.00968\n",
      "\tClass 1: 0.72936 ± 0.07543\n",
      "\tClass 2: 0.36458 ± 0.1458\n",
      "\tClass 3: 0.67923 ± 0.21848\n",
      "Mean recall: 0.5945 ± 0.03152\n",
      "\tClass 1: 0.63011 ± 0.05498\n",
      "\tClass 2: 0.58266 ± 0.08694\n",
      "\tClass 3: 0.54471 ± 0.06998\n",
      "Mean f1_score: 0.61546 ± 0.02555\n",
      "\tClass 1: 0.67356 ± 0.04713\n",
      "\tClass 2: 0.43759 ± 0.1079\n",
      "\tClass 3: 0.59352 ± 0.13601\n",
      "Training SVM model with kernel: sigmoid and C: 10.0\n",
      "Mean accuracy: 0.7121 ± 0.01089\n",
      "\tClass 1: 0.71228 ± 0.04624\n",
      "\tClass 2: 0.72106 ± 0.04658\n",
      "\tClass 3: 0.69508 ± 0.00908\n",
      "Mean precision: 0.64092 ± 0.01634\n",
      "\tClass 1: 0.55751 ± 0.19178\n",
      "\tClass 2: 0.64067 ± 0.23107\n",
      "\tClass 3: 0.48164 ± 0.26509\n",
      "Mean recall: 0.56421 ± 0.01481\n",
      "\tClass 1: 0.64975 ± 0.02676\n",
      "\tClass 2: 0.53395 ± 0.06313\n",
      "\tClass 3: 0.48311 ± 0.05261\n",
      "Mean f1_score: 0.58373 ± 0.014\n",
      "\tClass 1: 0.58477 ± 0.12215\n",
      "\tClass 2: 0.56758 ± 0.13436\n",
      "\tClass 3: 0.46174 ± 0.15045\n"
     ]
    }
   ],
   "source": [
    "kernel_C = [\n",
    "  (\"linear\", 0.1),\n",
    "  (\"linear\", 1.0),\n",
    "  (\"linear\", 10.0),\n",
    "  (\"poly\", 0.1),\n",
    "  (\"poly\", 1.0),\n",
    "  (\"poly\", 10.0),\n",
    "  (\"rbf\", 0.1),\n",
    "  (\"rbf\", 1.0),\n",
    "  (\"rbf\", 10.0),\n",
    "  (\"sigmoid\", 0.1),\n",
    "  (\"sigmoid\", 1.0),\n",
    "  (\"sigmoid\", 10.0)\n",
    "]\n",
    "\n",
    "general_results_svm = []\n",
    "class_results_svm = []\n",
    "\n",
    "for (kernel, C) in kernel_C\n",
    "  hyperparameters = Dict(\n",
    "    :kernel => kernel,\n",
    "    :C => C,\n",
    "    :gamma => \"auto\",\n",
    "    :probability => true,\n",
    "  )\n",
    "\n",
    "  println(\"Training SVM model with kernel: \", kernel, \" and C: \", C)\n",
    "\n",
    "  gr, cr = modelCrossValidation(\n",
    "    :SVC,\n",
    "    hyperparameters,\n",
    "    inputs,\n",
    "    targets,\n",
    "    fold_indices;\n",
    "    metricsToSave=metrics_to_save,\n",
    "    normalizationType=:zeroMean,\n",
    "    applyPCA=true,\n",
    "    pcaComponents=0.95,\n",
    "    applySmote=true,\n",
    "    smotePercentages=smote_percentage,\n",
    "    smoteNeighbors=k,\n",
    "    verbose=false\n",
    "  )\n",
    "\n",
    "  push!(general_results_svm, gr)\n",
    "  push!(class_results_svm, cr)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors\n",
    "\n",
    "The KNN model will be trained with the following hyperparameters:\n",
    "\n",
    "- $k \\in \\{1, 3, 5, 7, 9, 11, 13, 15\\}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNN model with n_neighbors: 1\n",
      "Mean accuracy: 0.73751 ± 0.01565\n",
      "\tClass 1: 0.7545 ± 0.04164\n",
      "\tClass 2: 0.71773 ± 0.05964\n",
      "\tClass 3: 0.73033 ± 0.05876\n",
      "Mean precision: 0.66871 ± 0.01447\n",
      "\tClass 1: 0.67884 ± 0.18015\n",
      "\tClass 2: 0.56378 ± 0.26448\n",
      "\tClass 3: 0.55609 ± 0.23756\n",
      "Mean recall: 0.60128 ± 0.02615\n",
      "\tClass 1: 0.59629 ± 0.06084\n",
      "\tClass 2: 0.59107 ± 0.08374\n",
      "\tClass 3: 0.5657 ± 0.02985\n",
      "Mean f1_score: 0.62198 ± 0.02152\n",
      "\tClass 1: 0.62215 ± 0.10402\n",
      "\tClass 2: 0.55846 ± 0.18406\n",
      "\tClass 3: 0.54109 ± 0.14531\n",
      "Training KNN model with n_neighbors: 3\n",
      "Mean accuracy: 0.73626 ± 0.01877\n",
      "\tClass 1: 0.75473 ± 0.03991\n",
      "\tClass 2: 0.72835 ± 0.07282\n",
      "\tClass 3: 0.70592 ± 0.04884\n",
      "Mean precision: 0.67211 ± 0.01515\n",
      "\tClass 1: 0.6805 ± 0.20443\n",
      "\tClass 2: 0.64106 ± 0.22487\n",
      "\tClass 3: 0.47295 ± 0.24338\n",
      "Mean recall: 0.5945 ± 0.03068\n",
      "\tClass 1: 0.59318 ± 0.06569\n",
      "\tClass 2: 0.59466 ± 0.06098\n",
      "\tClass 3: 0.55313 ± 0.03988\n",
      "Mean f1_score: 0.61785 ± 0.02564\n",
      "\tClass 1: 0.61957 ± 0.1261\n",
      "\tClass 2: 0.60096 ± 0.15506\n",
      "\tClass 3: 0.48472 ± 0.13867\n",
      "Training KNN model with n_neighbors: 5\n",
      "Mean accuracy: 0.73538 ± 0.01578\n",
      "\tClass 1: 0.7382 ± 0.05928\n",
      "\tClass 2: 0.69673 ± 0.07542\n",
      "\tClass 3: 0.74955 ± 0.05782\n",
      "Mean precision: 0.68832 ± 0.01341\n",
      "\tClass 1: 0.58619 ± 0.25831\n",
      "\tClass 2: 0.48677 ± 0.28433\n",
      "\tClass 3: 0.77263 ± 0.01933\n",
      "Mean recall: 0.59224 ± 0.02639\n",
      "\tClass 1: 0.584 ± 0.04994\n",
      "\tClass 2: 0.59208 ± 0.04659\n",
      "\tClass 3: 0.58915 ± 0.05478\n",
      "Mean f1_score: 0.61863 ± 0.02246\n",
      "\tClass 1: 0.55499 ± 0.14099\n",
      "\tClass 2: 0.49668 ± 0.16032\n",
      "\tClass 3: 0.66686 ± 0.02954\n",
      "Training KNN model with n_neighbors: 7\n",
      "Mean accuracy: 0.74213 ± 0.01492\n",
      "\tClass 1: 0.74252 ± 0.06012\n",
      "\tClass 2: 0.71976 ± 0.06055\n",
      "\tClass 3: 0.74207 ± 0.0679\n",
      "Mean precision: 0.70058 ± 0.01587\n",
      "\tClass 1: 0.61198 ± 0.26699\n",
      "\tClass 2: 0.58651 ± 0.26496\n",
      "\tClass 3: 0.6898 ± 0.22941\n",
      "Mean recall: 0.60217 ± 0.02211\n",
      "\tClass 1: 0.59591 ± 0.09047\n",
      "\tClass 2: 0.63212 ± 0.07927\n",
      "\tClass 3: 0.57225 ± 0.0646\n",
      "Mean f1_score: 0.62624 ± 0.0201\n",
      "\tClass 1: 0.56319 ± 0.12432\n",
      "\tClass 2: 0.57518 ± 0.1595\n",
      "\tClass 3: 0.60457 ± 0.12944\n",
      "Training KNN model with n_neighbors: 9\n",
      "Mean accuracy: 0.73747 ± 0.01493\n",
      "\tClass 1: 0.74772 ± 0.05831\n",
      "\tClass 2: 0.71006 ± 0.07547\n",
      "\tClass 3: 0.73349 ± 0.07063\n",
      "Mean precision: 0.70164 ± 0.01543\n",
      "\tClass 1: 0.69545 ± 0.21774\n",
      "\tClass 2: 0.58579 ± 0.2666\n",
      "\tClass 3: 0.60946 ± 0.28538\n",
      "Mean recall: 0.59564 ± 0.02452\n",
      "\tClass 1: 0.60148 ± 0.09028\n",
      "\tClass 2: 0.64587 ± 0.05775\n",
      "\tClass 3: 0.54722 ± 0.04653\n",
      "Mean f1_score: 0.62119 ± 0.02181\n",
      "\tClass 1: 0.61814 ± 0.11776\n",
      "\tClass 2: 0.57722 ± 0.14974\n",
      "\tClass 3: 0.53851 ± 0.13031\n",
      "Training KNN model with n_neighbors: 11\n",
      "Mean accuracy: 0.7349 ± 0.01605\n",
      "\tClass 1: 0.74614 ± 0.06632\n",
      "\tClass 2: 0.6965 ± 0.07663\n",
      "\tClass 3: 0.73869 ± 0.06211\n",
      "Mean precision: 0.70279 ± 0.00853\n",
      "\tClass 1: 0.6963 ± 0.22295\n",
      "\tClass 2: 0.49767 ± 0.28207\n",
      "\tClass 3: 0.69938 ± 0.21758\n",
      "Mean recall: 0.59066 ± 0.02632\n",
      "\tClass 1: 0.61648 ± 0.0994\n",
      "\tClass 2: 0.61563 ± 0.05582\n",
      "\tClass 3: 0.55847 ± 0.07326\n",
      "Mean f1_score: 0.61709 ± 0.02153\n",
      "\tClass 1: 0.62309 ± 0.11918\n",
      "\tClass 2: 0.50601 ± 0.14236\n",
      "\tClass 3: 0.59514 ± 0.09962\n",
      "Training KNN model with n_neighbors: 13\n",
      "Mean accuracy: 0.72684 ± 0.01653\n",
      "\tClass 1: 0.73665 ± 0.07608\n",
      "\tClass 2: 0.68543 ± 0.08018\n",
      "\tClass 3: 0.73259 ± 0.06399\n",
      "Mean precision: 0.69842 ± 0.00729\n",
      "\tClass 1: 0.69565 ± 0.23844\n",
      "\tClass 2: 0.49223 ± 0.28336\n",
      "\tClass 3: 0.69074 ± 0.21818\n",
      "Mean recall: 0.57733 ± 0.02677\n",
      "\tClass 1: 0.59024 ± 0.09822\n",
      "\tClass 2: 0.62419 ± 0.07451\n",
      "\tClass 3: 0.54148 ± 0.06776\n",
      "Mean f1_score: 0.60518 ± 0.02199\n",
      "\tClass 1: 0.60568 ± 0.12969\n",
      "\tClass 2: 0.50064 ± 0.13716\n",
      "\tClass 3: 0.58265 ± 0.10262\n",
      "Training KNN model with n_neighbors: 15\n",
      "Mean accuracy: 0.73196 ± 0.01289\n",
      "\tClass 1: 0.73822 ± 0.07329\n",
      "\tClass 2: 0.68791 ± 0.07635\n",
      "\tClass 3: 0.74388 ± 0.0619\n",
      "Mean precision: 0.70233 ± 0.00827\n",
      "\tClass 1: 0.691 ± 0.22863\n",
      "\tClass 2: 0.48993 ± 0.27952\n",
      "\tClass 3: 0.70645 ± 0.22037\n",
      "Mean recall: 0.58501 ± 0.02436\n",
      "\tClass 1: 0.60452 ± 0.09122\n",
      "\tClass 2: 0.60779 ± 0.07195\n",
      "\tClass 3: 0.56425 ± 0.07015\n",
      "Mean f1_score: 0.61289 ± 0.0184\n",
      "\tClass 1: 0.61332 ± 0.1208\n",
      "\tClass 2: 0.49546 ± 0.1362\n",
      "\tClass 3: 0.60233 ± 0.10463\n"
     ]
    }
   ],
   "source": [
    "n_neighbors = [1, 3, 5, 7, 9, 11, 13, 15]\n",
    "\n",
    "general_results_knn = []\n",
    "class_results_knn = []\n",
    "\n",
    "open(\"warnings.log\", \"w\") do file\n",
    "  redirect_stderr(file) do # redirect warnings associated with joblib\n",
    "    for n in n_neighbors\n",
    "      hyperparameters = Dict(\n",
    "        :n_neighbors => n,\n",
    "        :weights => \"uniform\",\n",
    "        :metric => \"euclidean\",\n",
    "      )\n",
    "\n",
    "      println(\"Training KNN model with n_neighbors: \", n)\n",
    "\n",
    "      gr, cr = modelCrossValidation(\n",
    "        :KNN,\n",
    "        hyperparameters,\n",
    "        inputs,\n",
    "        targets,\n",
    "        fold_indices;\n",
    "        metricsToSave=metrics_to_save,\n",
    "        normalizationType=:zeroMean,\n",
    "        applyPCA=true,\n",
    "        pcaComponents=0.95,\n",
    "        applySmote=true,\n",
    "        smotePercentages=smote_percentage,\n",
    "        smoteNeighbors=k,\n",
    "        verbose=false\n",
    "      )\n",
    "\n",
    "      push!(general_results_knn, gr)\n",
    "      push!(class_results_knn, cr)\n",
    "    end\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the results\n",
    "\n",
    "In order to be able to compare the results of the models without running the training again, we will save the results in a dictionary. The dictionary will have the following structure:\n",
    "\n",
    "```julia\n",
    "{\n",
    "    :model: {\n",
    "        'num_trained_models': int,\n",
    "        'parameters': Dict{String, Any},\n",
    "        'general_results': [\n",
    "            {\n",
    "                'accuracy': AbstractVector{Float64},\n",
    "                'precision': AbstractVector{Float64},\n",
    "                'recall': AbstractVector{Float64},\n",
    "                'f1_score': AbstractVector{Float64},\n",
    "            },\n",
    "            ... # One element for each trained model\n",
    "        ],\n",
    "        'class_results': [\n",
    "            [\n",
    "                {\n",
    "                    'accuracy': AbstractVector{Float64},\n",
    "                    'precision': AbstractVector{Float64},\n",
    "                    'recall': AbstractVector{Float64},\n",
    "                    'f1_score': AbstractVector{Float64},\n",
    "                },\n",
    "                ... # One element for each class\n",
    "            ],\n",
    "            ... # One element for each trained model\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "The results of all approaches will be avaiable in the `results` dictionary. The filename with the results of individual models of this first approach will be `1_individual_results.jl`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = \"results/\"\n",
    "if !isdir(results_folder)\n",
    "  mkdir(results_folder)\n",
    "end\n",
    "\n",
    "filename = results_folder * \"4_individual_results.jl\"\n",
    "\n",
    "# Separete the kernel and C values of the hyperparameter list for SVM\n",
    "kernels = [item[1] for item in kernel_C]\n",
    "C_values = [item[2] for item in kernel_C]\n",
    "\n",
    "# Create a dictionary with the results of ANN, DT, SVM, and KNN\n",
    "obj = Dict(\n",
    "  :ANN => Dict(\n",
    "    \"num_trained_models\" => length(general_results_ann),\n",
    "    \"parameters\" => Dict(\n",
    "      \"topology\" => topologies\n",
    "    ),\n",
    "    \"general_results\" => general_results_ann,\n",
    "    \"class_results\" => class_results_ann\n",
    "  ),\n",
    "  :scikit_ANN => Dict(\n",
    "    \"num_trained_models\" => length(general_results_scikit_ann),\n",
    "    \"parameters\" => Dict(\n",
    "      \"hidden_layer_sizes\" => topologies\n",
    "    ),\n",
    "    \"general_results\" => general_results_scikit_ann,\n",
    "    \"class_results\" => class_results_scikit_ann\n",
    "  ),\n",
    "  :DT => Dict(\n",
    "    \"num_trained_models\" => length(general_results_dt),\n",
    "    \"parameters\" => Dict(\n",
    "      \"max_depth\" => max_depths\n",
    "    ),\n",
    "    \"general_results\" => general_results_dt,\n",
    "    \"class_results\" => class_results_dt\n",
    "  ),\n",
    "  :SVM => Dict(\n",
    "    \"num_trained_models\" => length(general_results_svm),\n",
    "    \"parameters\" => Dict(\n",
    "      \"kernel\" => kernels,\n",
    "      \"C\" => C_values\n",
    "    ),\n",
    "    \"general_results\" => general_results_svm,\n",
    "    \"class_results\" => class_results_svm\n",
    "  ),\n",
    "  :KNN => Dict(\n",
    "    \"num_trained_models\" => length(general_results_knn),\n",
    "    \"parameters\" => Dict(\n",
    "      \"n_neighbors\" => n_neighbors\n",
    "    ),\n",
    "    \"general_results\" => general_results_knn,\n",
    "    \"class_results\" => class_results_knn\n",
    "  )\n",
    ")\n",
    "\n",
    "# Save the results\n",
    "open(filename, \"w\") do file\n",
    "  serialize(file, obj)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base model plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = \"results/\"\n",
    "filename = results_folder * \"4_individual_results.jl\"\n",
    "\n",
    "# Load the results\n",
    "loaded_obj = open(filename, \"r\") do file\n",
    "  deserialize(file)\n",
    "end\n",
    "\n",
    "model_names, metrics, metric_means, metric_stds, metric_maxes = aggregateMetrics(loaded_obj)\n",
    "\n",
    "# Plot metrics for each algorithm\n",
    "plotMetricsAlgorithm(loaded_obj, output_dir=\"./plots/Approach4\", ylim=(0.6, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison of Hyperparameter Configurations for DT (Sorted by F1_Score):\n",
      "┌────────────────────┬──────────┬───────────┬──────────┬──────────┐\n",
      "│\u001b[1m      Configuration \u001b[0m│\u001b[1m Accuracy \u001b[0m│\u001b[1m Precision \u001b[0m│\u001b[1m   Recall \u001b[0m│\u001b[1m F1-Score \u001b[0m│\n",
      "├────────────────────┼──────────┼───────────┼──────────┼──────────┤\n",
      "│      max_depth: 10 │ 0.738521 │  0.644719 │  0.60904 │    0.622 │\n",
      "│ max_depth: nothing │ 0.721066 │   0.61858 │ 0.586441 │ 0.598321 │\n",
      "│       max_depth: 3 │ 0.732337 │  0.653709 │ 0.613559 │ 0.595028 │\n",
      "│       max_depth: 5 │ 0.720757 │  0.686536 │ 0.577401 │ 0.589566 │\n",
      "│      max_depth: 15 │  0.71221 │  0.626006 │ 0.566102 │ 0.586023 │\n",
      "│      max_depth: 20 │ 0.711139 │  0.625714 │ 0.563986 │  0.58397 │\n",
      "└────────────────────┴──────────┴───────────┴──────────┴──────────┘\n",
      "Results for DT saved to ./tables/Approach4/.\n",
      "\n",
      "Comparison of Hyperparameter Configurations for KNN (Sorted by F1_Score):\n",
      "┌─────────────────┬──────────┬───────────┬──────────┬──────────┐\n",
      "│\u001b[1m   Configuration \u001b[0m│\u001b[1m Accuracy \u001b[0m│\u001b[1m Precision \u001b[0m│\u001b[1m   Recall \u001b[0m│\u001b[1m F1-Score \u001b[0m│\n",
      "├─────────────────┼──────────┼───────────┼──────────┼──────────┤\n",
      "│  n_neighbors: 7 │ 0.757417 │  0.719531 │ 0.627119 │ 0.649926 │\n",
      "│  n_neighbors: 9 │ 0.757157 │  0.712991 │ 0.625142 │ 0.649629 │\n",
      "│  n_neighbors: 1 │ 0.753967 │  0.682724 │ 0.631638 │ 0.644894 │\n",
      "│ n_neighbors: 11 │ 0.754807 │  0.712699 │ 0.620612 │ 0.644109 │\n",
      "│  n_neighbors: 3 │ 0.751453 │  0.691269 │ 0.616949 │  0.63857 │\n",
      "│ n_neighbors: 13 │ 0.750844 │  0.704351 │ 0.614949 │ 0.637799 │\n",
      "│  n_neighbors: 5 │  0.74768 │  0.703221 │ 0.611299 │ 0.635103 │\n",
      "│ n_neighbors: 15 │ 0.743813 │   0.71254 │ 0.608154 │ 0.629392 │\n",
      "└─────────────────┴──────────┴───────────┴──────────┴──────────┘\n",
      "Results for KNN saved to ./tables/Approach4/.\n",
      "\n",
      "Comparison of Hyperparameter Configurations for SVM (Sorted by F1_Score):\n",
      "┌──────────────────────────┬──────────┬───────────┬──────────┬──────────┐\n",
      "│\u001b[1m            Configuration \u001b[0m│\u001b[1m Accuracy \u001b[0m│\u001b[1m Precision \u001b[0m│\u001b[1m   Recall \u001b[0m│\u001b[1m F1-Score \u001b[0m│\n",
      "├──────────────────────────┼──────────┼───────────┼──────────┼──────────┤\n",
      "│   C: 1.0, kernel: linear │ 0.797162 │    0.7326 │ 0.687006 │ 0.699506 │\n",
      "│      C: 1.0, kernel: rbf │ 0.794635 │  0.752734 │ 0.681356 │ 0.698081 │\n",
      "│   C: 0.1, kernel: linear │ 0.790948 │  0.729343 │ 0.677966 │ 0.692044 │\n",
      "│     C: 10.0, kernel: rbf │ 0.786194 │   0.72092 │ 0.675706 │  0.69005 │\n",
      "│  C: 10.0, kernel: linear │ 0.787615 │  0.721486 │ 0.675706 │   0.6893 │\n",
      "│     C: 1.0, kernel: poly │ 0.783044 │  0.747236 │ 0.662147 │ 0.681843 │\n",
      "│  C: 0.1, kernel: sigmoid │ 0.781378 │  0.721187 │ 0.664407 │  0.67789 │\n",
      "│    C: 10.0, kernel: poly │ 0.779924 │   0.72017 │ 0.662514 │ 0.676316 │\n",
      "│      C: 0.1, kernel: rbf │  0.76473 │  0.755688 │ 0.635028 │ 0.652314 │\n",
      "│  C: 1.0, kernel: sigmoid │ 0.748606 │  0.686168 │ 0.613559 │  0.63134 │\n",
      "│ C: 10.0, kernel: sigmoid │  0.73029 │  0.667685 │ 0.587769 │ 0.605696 │\n",
      "│     C: 0.1, kernel: poly │ 0.639724 │  0.700786 │ 0.433898 │ 0.457388 │\n",
      "└──────────────────────────┴──────────┴───────────┴──────────┴──────────┘\n",
      "Results for SVM saved to ./tables/Approach4/.\n",
      "\n",
      "Comparison of Hyperparameter Configurations for scikit_ANN (Sorted by F1_Score):\n",
      "┌──────────────────────────────┬──────────┬───────────┬──────────┬──────────┐\n",
      "│\u001b[1m                Configuration \u001b[0m│\u001b[1m Accuracy \u001b[0m│\u001b[1m Precision \u001b[0m│\u001b[1m   Recall \u001b[0m│\u001b[1m F1-Score \u001b[0m│\n",
      "├──────────────────────────────┼──────────┼───────────┼──────────┼──────────┤\n",
      "│ hidden_layer_sizes: [64, 64] │ 0.785962 │  0.733414 │ 0.666667 │  0.68409 │\n",
      "│ hidden_layer_sizes: [32, 32] │ 0.782927 │  0.740017 │ 0.662373 │ 0.683006 │\n",
      "│     hidden_layer_sizes: [16] │ 0.781854 │  0.738129 │ 0.659661 │  0.68098 │\n",
      "│ hidden_layer_sizes: [16, 16] │ 0.780776 │  0.729242 │ 0.661695 │ 0.680274 │\n",
      "│     hidden_layer_sizes: [32] │ 0.777475 │  0.746029 │ 0.654463 │ 0.675494 │\n",
      "│ hidden_layer_sizes: [32, 16] │ 0.777932 │  0.732506 │ 0.655819 │ 0.674657 │\n",
      "│     hidden_layer_sizes: [64] │ 0.772364 │  0.732947 │ 0.651302 │ 0.668745 │\n",
      "│ hidden_layer_sizes: [64, 32] │ 0.768488 │  0.732514 │ 0.643941 │ 0.664451 │\n",
      "└──────────────────────────────┴──────────┴───────────┴──────────┴──────────┘\n",
      "Results for scikit_ANN saved to ./tables/Approach4/.\n",
      "\n",
      "Comparison of Hyperparameter Configurations for ANN (Sorted by F1_Score):\n",
      "┌────────────────────┬──────────┬───────────┬──────────┬──────────┐\n",
      "│\u001b[1m      Configuration \u001b[0m│\u001b[1m Accuracy \u001b[0m│\u001b[1m Precision \u001b[0m│\u001b[1m   Recall \u001b[0m│\u001b[1m F1-Score \u001b[0m│\n",
      "├────────────────────┼──────────┼───────────┼──────────┼──────────┤\n",
      "│ topology: [64, 32] │ 0.715766 │  0.543304 │ 0.593107 │ 0.544384 │\n",
      "│ topology: [32, 16] │ 0.714042 │   0.51214 │ 0.587345 │ 0.541869 │\n",
      "│ topology: [64, 64] │ 0.708921 │  0.539827 │ 0.580634 │ 0.535133 │\n",
      "│ topology: [16, 16] │ 0.682756 │  0.491186 │ 0.547571 │ 0.510907 │\n",
      "│ topology: [32, 32] │ 0.668036 │  0.490523 │ 0.538845 │ 0.498401 │\n",
      "│     topology: [64] │ 0.676694 │  0.493729 │ 0.536271 │ 0.494191 │\n",
      "│     topology: [32] │ 0.652168 │  0.461682 │ 0.499887 │ 0.472631 │\n",
      "│     topology: [16] │ 0.650193 │  0.500096 │  0.50474 │ 0.466599 │\n",
      "└────────────────────┴──────────┴───────────┴──────────┴──────────┘\n",
      "Results for ANN saved to ./tables/Approach4/.\n"
     ]
    }
   ],
   "source": [
    "generateAlgorithmTables(loaded_obj, sort_by=:F1_Score, rev=true, output_dir=\"./tables/Approach4/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCombinedMetrics(model_names, metrics, metric_means, metric_stds, output_dir=\"./plots/Approach4/\", show=true, ylim=(0.6, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateComparisonTable(model_names, metrics, metric_maxes; sort_by=:accuracy, rev=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble models\n",
    "\n",
    "After training the individual models, we will train an ensemble model with the three best models. The method used to combine the models will be:\n",
    "\n",
    "- **Majority voting**\n",
    "- **Weighted voting**\n",
    "- **Naive Bayes**\n",
    "- **Stacking** (using a logistic regression as the meta-model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best models\n",
    "estimators = [:ANN, :SVC, :KNN]\n",
    "hyperparameters = Vector{Dict}([\n",
    "  Dict(\n",
    "    :hidden_layer_sizes => (32),\n",
    "    :learning_rate_init => 0.01,\n",
    "    :max_iter => 100,\n",
    "    :early_stopping => true,\n",
    "    :tol => 0,\n",
    "    :validation_fraction => 0.15,\n",
    "    :n_iter_no_change => 10,\n",
    "    :epsilon => 0.0001\n",
    "  ),\n",
    "  Dict(\n",
    "  :kernel => \"rbf\",\n",
    "  :C => 1.0,\n",
    "  :gamma => \"auto\",\n",
    "  :probability => true,\n",
    "  ),\n",
    "  Dict(\n",
    "    :n_neighbors => 11,\n",
    "    :weights => \"uniform\",\n",
    "    :metric => \"euclidean\",\n",
    "  )])\n",
    "\n",
    "# Define ensembles\n",
    "ensembles = [\n",
    "  Dict(\n",
    "    :type => :Voting,\n",
    "    :hyperparameters => Dict(\n",
    "    )\n",
    "  ),\n",
    "  Dict(\n",
    "    :type => :Voting,\n",
    "    :hyperparameters => Dict(\n",
    "      :voting => \"soft\",\n",
    "      :weights => [0.5, 0.2, 0.3]\n",
    "    )\n",
    "  ),\n",
    "  Dict(\n",
    "    :type => :Stacking,\n",
    "    :hyperparameters => Dict(\n",
    "      :final_estimator => LogisticRegression()\n",
    "    )\n",
    "  )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (index, ensemble) in enumerate(ensembles)\n",
    "    println(\"Training ensemble \", ensemble[:type])\n",
    "    metrics, class_results = trainClassEnsemble(\n",
    "        estimators,\n",
    "        hyperparameters,\n",
    "        (inputs, targets_label_encoded),\n",
    "        fold_indices;\n",
    "        ensembleType = ensemble[:type],\n",
    "        ensembleHyperParameters = ensemble[:hyperparameters],\n",
    "        metricsToSave = metrics_to_save,\n",
    "        repetitionsTraining = 5,\n",
    "        applyPCA = true,\n",
    "        pcaComponents = 0.95,\n",
    "        applySmote=true,\n",
    "        smotePercentages=smote_percentage,\n",
    "        smoteNeighbors=k,\n",
    "        verbose=false\n",
    "    )\n",
    "    ensemble[:results] = metrics\n",
    "    ensemble[:class_results] = class_results\n",
    "    println(\"------------------------------------\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = \"results/\"\n",
    "if !isdir(results_folder)\n",
    "  mkdir(results_folder)\n",
    "end\n",
    "\n",
    "filename = results_folder * \"4_ensemble_results.jl\"\n",
    "\n",
    "# Create a dictionary with the results of ANN, DT, SVM, and KNN\n",
    "obj = Dict(\n",
    "  :Voting_Hard => Dict(\n",
    "    \"general_results\" => ensembles[1][:results],\n",
    "    \"class_results\" => ensembles[1][:class_results]\n",
    "  ),\n",
    "  :Voting_Soft => Dict(\n",
    "    \"general_results\" => ensembles[2][:results],\n",
    "    \"class_results\" => ensembles[2][:class_results]\n",
    "  ),\n",
    "  :Stacking => Dict(\n",
    "    \"general_results\" => ensembles[3][:results],\n",
    "    \"class_results\" => ensembles[3][:class_results]\n",
    "  )\n",
    ")\n",
    "\n",
    "# Save the results\n",
    "open(filename, \"w\") do file\n",
    "  serialize(file, obj)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = results_folder * \"4_ensemble_results.jl\"\n",
    "\n",
    "# Load the results\n",
    "loaded_obj = open(filename, \"r\") do file\n",
    "  deserialize(file)\n",
    "end\n",
    "\n",
    "model_names, metrics, metric_means, metric_stds, metric_means_class, metric_stds_class, metric_maxes, metric_maxes_class = aggregateMetrics(loaded_obj, ensemble=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCombinedMetrics(model_names, metrics, metric_maxes_class, metric_stds, output_dir=\"./plots/Approach4/ensembles\", show=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateComparisonTable(model_names, metrics, metric_maxes_class; sort_by=:f1_score, rev=true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.1",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
